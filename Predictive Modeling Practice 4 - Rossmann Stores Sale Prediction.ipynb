{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fengy\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold, RandomizedSearchCV\n",
    "from sklearn.cross_validation import cross_val_predict, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import ensemble\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some metrics function\n",
    "def ToWeight(y):\n",
    "    w = np.zeros(y.shape, dtype=float)\n",
    "    ind = y != 0\n",
    "    w[ind] = 1./(y[ind]**2)\n",
    "    return w\n",
    "\n",
    "\n",
    "def rmspe(yhat, y):\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean( w * (y - yhat)**2 ))\n",
    "    return rmspe\n",
    "\n",
    "\n",
    "def rmspe_xg(yhat, y):\n",
    "    # y = y.values\n",
    "    y = y.get_label()\n",
    "    y = np.exp(y) - 1\n",
    "    yhat = np.exp(yhat) - 1\n",
    "    w = ToWeight(y)\n",
    "    rmspe = np.sqrt(np.mean(w * (y - yhat)**2))\n",
    "    return \"rmspe\", rmspe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fengy\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_store = pd.read_csv('store.csv')\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>Jan,Apr,Jul,Oct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
       "0      1         c          a               1270.0                        9.0   \n",
       "1      2         a          a                570.0                       11.0   \n",
       "\n",
       "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
       "0                    2008.0       0              NaN              NaN   \n",
       "1                    2007.0       1             13.0           2010.0   \n",
       "\n",
       "     PromoInterval  \n",
       "0              NaN  \n",
       "1  Jan,Apr,Jul,Oct  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_store.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>6064</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0      1          5  2015-07-31   5263        555     1      1            0   \n",
       "1      2          5  2015-07-31   6064        625     1      1            0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              1  \n",
       "1              1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Store  DayOfWeek        Date  Open  Promo StateHoliday  SchoolHoliday\n",
       "0   1      1          4  2015-09-17   1.0      1            0              0\n",
       "1   2      3          4  2015-09-17   1.0      1            0              0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data cleaning & Building Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding time columns\n",
    "df_train.fillna(0, inplace = True)\n",
    "df_train['Date'] = pd.to_datetime(df_train['Date'])\n",
    "df_train['Month'] = df_train.Date.apply(lambda dt: dt.month)\n",
    "df_train['Year'] = df_train.Date.apply(lambda dt: dt.year)\n",
    "df_train['Day'] = df_train.Date.apply(lambda dt: dt.day)\n",
    "df_train['wom'] = df_train.Date.apply(lambda dt: (dt.day-1)//7 + 1)\n",
    "df_train['SchoolHoliday'] = df_train['SchoolHoliday'].astype(int) \n",
    "df_train['Open'] = df_train['Open'].map(lambda x : float(x))\n",
    "df_train = df_train.merge(df_store,  on = 'Store')\n",
    "\n",
    "df_test.fillna(0, inplace=True)\n",
    "df_test['Date'] = pd.to_datetime(df_test['Date'])\n",
    "df_test['Month'] = df_test.Date.apply(lambda dt: dt.month)\n",
    "df_test['Year'] = df_test.Date.apply(lambda dt: dt.year)\n",
    "df_test['Day'] = df_test.Date.apply(lambda dt: dt.day)\n",
    "df_test['wom'] = df_test.Date.apply(lambda dt: (dt.day-1)//7 + 1)\n",
    "df_test['SchoolHoliday'] = df_test['SchoolHoliday'].astype(int) \n",
    "df_test = df_test.merge(df_store,  on = 'Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add previous time period data\n",
    "df_train['prev_wom'] = df_train.groupby(['Month','DayOfWeek','wom','Store'])['Sales'].shift(1)\n",
    "df_train['prev_wom'].fillna(df_train['Sales'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another test dataset from train dataset (the previous year )\n",
    "from datetime import datetime\n",
    "for_test = df_train[(df_train[\"Date\"]>=datetime(2014,7,1)) & \\\n",
    "                    (df_train[\"Date\"]<=datetime(2014,9,30))]\n",
    "\n",
    "for_test = for_test[['Month','DayOfWeek','wom','Store','Sales']]\n",
    "for_test.columns = ['Month','DayOfWeek','wom','Store','prev_wom']\n",
    "df_test = pd.merge(df_test,for_test,how='left', \\\n",
    "                   on=['Month','DayOfWeek','wom','Store'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_test_na = df_train.groupby('Store')['prev_wom'].median().reset_index()\n",
    "for_test_na.columns = ['Store','prev_wom_change']\n",
    "df_test = pd.merge(df_test,for_test_na,how='left',on=['Store'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>...</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "      <th>prev_wom</th>\n",
       "      <th>prev_wom_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3740.0</td>\n",
       "      <td>4209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>857</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-09-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4383.0</td>\n",
       "      <td>4209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1713</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-09-15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4381.0</td>\n",
       "      <td>4209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2569</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-09-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3676.0</td>\n",
       "      <td>4209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3425</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2015-09-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4209.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  Store  DayOfWeek       Date  Open  Promo StateHoliday  SchoolHoliday  \\\n",
       "0     1      1          4 2015-09-17   1.0      1            0              0   \n",
       "1   857      1          3 2015-09-16   1.0      1            0              0   \n",
       "2  1713      1          2 2015-09-15   1.0      1            0              0   \n",
       "3  2569      1          1 2015-09-14   1.0      1            0              0   \n",
       "4  3425      1          7 2015-09-13   0.0      0            0              0   \n",
       "\n",
       "   Month  Year       ...         Assortment  CompetitionDistance  \\\n",
       "0      9  2015       ...                  a               1270.0   \n",
       "1      9  2015       ...                  a               1270.0   \n",
       "2      9  2015       ...                  a               1270.0   \n",
       "3      9  2015       ...                  a               1270.0   \n",
       "4      9  2015       ...                  a               1270.0   \n",
       "\n",
       "  CompetitionOpenSinceMonth CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  \\\n",
       "0                       9.0                   2008.0       0              NaN   \n",
       "1                       9.0                   2008.0       0              NaN   \n",
       "2                       9.0                   2008.0       0              NaN   \n",
       "3                       9.0                   2008.0       0              NaN   \n",
       "4                       9.0                   2008.0       0              NaN   \n",
       "\n",
       "   Promo2SinceYear  PromoInterval  prev_wom  prev_wom_change  \n",
       "0              NaN            NaN    3740.0           4209.0  \n",
       "1              NaN            NaN    4383.0           4209.0  \n",
       "2              NaN            NaN    4381.0           4209.0  \n",
       "3              NaN            NaN    3676.0           4209.0  \n",
       "4              NaN            NaN       0.0           4209.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.loc[df_test['prev_wom'].isnull(),'prev_wom']=df_test['prev_wom_change']\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with some categorical variables\n",
    "\n",
    "# Store Type\n",
    "df_train.loc[df_train['StoreType'] == 'a', 'StoreType'] = '1'\n",
    "df_train.loc[df_train['StoreType'] == 'b', 'StoreType'] = '2'\n",
    "df_train.loc[df_train['StoreType'] == 'c', 'StoreType'] = '3'\n",
    "df_train.loc[df_train['StoreType'] == 'd', 'StoreType'] = '4'\n",
    "\n",
    "df_test.loc[df_test['StoreType'] == 'a', 'StoreType'] = '1'\n",
    "df_test.loc[df_test['StoreType'] == 'b', 'StoreType'] = '2'\n",
    "df_test.loc[df_test['StoreType'] == 'c', 'StoreType'] = '3'\n",
    "df_test.loc[df_test['StoreType'] == 'd', 'StoreType'] = '4'\n",
    "\n",
    "# Assortment\n",
    "df_train.loc[df_train['Assortment'] == 'a', 'Assortment'] = '1'\n",
    "df_train.loc[df_train['Assortment'] == 'b', 'Assortment'] = '2'\n",
    "df_train.loc[df_train['Assortment'] == 'c', 'Assortment'] = '3'\n",
    "\n",
    "df_test.loc[df_test['Assortment'] == 'a', 'Assortment'] = '1'\n",
    "df_test.loc[df_test['Assortment'] == 'b', 'Assortment'] = '2'\n",
    "df_test.loc[df_test['Assortment'] == 'c', 'Assortment'] = '3'\n",
    "\n",
    "# Stateholiday\n",
    "df_train['StateHoliday'] = df_train['StateHoliday'].replace(0, '0')\n",
    "df_train.loc[df_train['StateHoliday'] == 'a', 'StateHoliday'] = '1'\n",
    "df_train.loc[df_train['StateHoliday'] == 'b', 'StateHoliday'] = '2'\n",
    "df_train.loc[df_train['StateHoliday'] == 'c', 'StateHoliday'] = '3'\n",
    "\n",
    "df_test['StateHoliday'] = df_test['StateHoliday'].replace(0, '0')\n",
    "df_test.loc[df_test['StateHoliday'] == 'a', 'StateHoliday'] = '1'\n",
    "df_test.loc[df_test['StateHoliday'] == 'b', 'StateHoliday'] = '2'\n",
    "df_test.loc[df_test['StateHoliday'] == 'c', 'StateHoliday'] = '3'\n",
    "\n",
    "# Promote interval\n",
    "df_train.loc[df_train['PromoInterval'].isnull(), 'PromoInterval'] = '1'\n",
    "df_train.loc[df_train['PromoInterval'] == 'Jan,Apr,Jul,Oct', 'PromoInterval'] = '2'\n",
    "df_train.loc[df_train['PromoInterval'] == 'Feb,May,Aug,Nov', 'PromoInterval'] = '3'\n",
    "df_train.loc[df_train['PromoInterval'] == 'Mar,Jun,Sept,Dec', 'PromoInterval'] = '4'\n",
    "\n",
    "\n",
    "df_test.loc[df_test['PromoInterval'].isnull(), 'PromoInterval'] = '1'\n",
    "df_test.loc[df_test['PromoInterval'] == 'Jan,Apr,Jul,Oct', 'PromoInterval'] = '2'\n",
    "df_test.loc[df_test['PromoInterval'] == 'Feb,May,Aug,Nov', 'PromoInterval'] = '3'\n",
    "df_test.loc[df_test['PromoInterval'] == 'Mar,Jun,Sept,Dec', 'PromoInterval'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the column of store average sales (using train dataset)\n",
    "df_train_custsales = df_train[['Store','Customers','Sales']]\n",
    "\n",
    "mean_data = df_train_custsales.groupby('Store'). \\\n",
    "            agg({'Sales':'mean','Customers':'mean'}).reset_index()\n",
    "\n",
    "df_train = df_train.merge(mean_data, on = 'Store')\n",
    "df_test = df_test.merge(mean_data, on = 'Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance data\n",
    "df_train['CompetitionDistance'].fillna(df_train['CompetitionDistance'].median(), inplace=True)\n",
    "df_train['CompetitionDistance'] = np.log(df_train.CompetitionDistance) + 1\n",
    "\n",
    "df_test['CompetitionDistance'].fillna(df_test['CompetitionDistance'].median(), inplace=True)\n",
    "df_test['CompetitionDistance'] = np.log(df_test.CompetitionDistance) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only the open days \n",
    "df_train = df_train[df_train[\"Open\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns\n",
    "df_train = df_train[df_train.columns.drop(['Day','Store','Date','CompetitionOpenSinceMonth', \\\n",
    "                                           'CompetitionOpenSinceYear','Promo2SinceWeek','Promo2SinceYear','PromoInterval','Year'])]\n",
    "\n",
    "df_test = df_test[df_test.columns.drop(['Day','Store','Date','CompetitionOpenSinceMonth', \\\n",
    "                                        'CompetitionOpenSinceYear','Promo2SinceWeek','Promo2SinceYear','PromoInterval','Year'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dummies\n",
    "df_train = pd.get_dummies(df_train, columns=['DayOfWeek', 'StateHoliday', \\\n",
    "                                             'StoreType', 'Assortment','Month'], dummy_na=False)\n",
    "\n",
    "df_test = pd.get_dummies(df_test, columns=['DayOfWeek', 'StateHoliday', \\\n",
    "                                           'StoreType', 'Assortment','Month'], dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding test the same column just like train does\n",
    "df_test['StateHoliday_2']=0\n",
    "df_test['StateHoliday_3']=0\n",
    "\n",
    "df_test['Month_1'] = 0\n",
    "df_test['Month_2'] = 0\n",
    "df_test['Month_3'] = 0\n",
    "df_test['Month_4'] = 0\n",
    "df_test['Month_5'] = 0\n",
    "df_test['Month_6'] = 0\n",
    "df_test['Month_7'] = 0\n",
    "df_test['Month_10'] = 0\n",
    "df_test['Month_11'] = 0\n",
    "df_test['Month_12'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>wom</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>prev_wom</th>\n",
       "      <th>prev_wom_change</th>\n",
       "      <th>Sales</th>\n",
       "      <th>...</th>\n",
       "      <th>Month_1</th>\n",
       "      <th>Month_2</th>\n",
       "      <th>Month_3</th>\n",
       "      <th>Month_4</th>\n",
       "      <th>Month_5</th>\n",
       "      <th>Month_6</th>\n",
       "      <th>Month_7</th>\n",
       "      <th>Month_10</th>\n",
       "      <th>Month_11</th>\n",
       "      <th>Month_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.146772</td>\n",
       "      <td>0</td>\n",
       "      <td>3740.0</td>\n",
       "      <td>4209.0</td>\n",
       "      <td>3945.704883</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>857</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.146772</td>\n",
       "      <td>0</td>\n",
       "      <td>4383.0</td>\n",
       "      <td>4209.0</td>\n",
       "      <td>3945.704883</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1713</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.146772</td>\n",
       "      <td>0</td>\n",
       "      <td>4381.0</td>\n",
       "      <td>4209.0</td>\n",
       "      <td>3945.704883</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2569</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.146772</td>\n",
       "      <td>0</td>\n",
       "      <td>3676.0</td>\n",
       "      <td>4209.0</td>\n",
       "      <td>3945.704883</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.146772</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4209.0</td>\n",
       "      <td>3945.704883</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  Open  Promo  SchoolHoliday  wom  CompetitionDistance  Promo2  \\\n",
       "0     1   1.0      1              0    3             8.146772       0   \n",
       "1   857   1.0      1              0    3             8.146772       0   \n",
       "2  1713   1.0      1              0    3             8.146772       0   \n",
       "3  2569   1.0      1              0    2             8.146772       0   \n",
       "4  3425   0.0      0              0    2             8.146772       0   \n",
       "\n",
       "   prev_wom  prev_wom_change        Sales    ...     Month_1  Month_2  \\\n",
       "0    3740.0           4209.0  3945.704883    ...           0        0   \n",
       "1    4383.0           4209.0  3945.704883    ...           0        0   \n",
       "2    4381.0           4209.0  3945.704883    ...           0        0   \n",
       "3    3676.0           4209.0  3945.704883    ...           0        0   \n",
       "4       0.0           4209.0  3945.704883    ...           0        0   \n",
       "\n",
       "   Month_3  Month_4  Month_5  Month_6  Month_7  Month_10  Month_11  Month_12  \n",
       "0        0        0        0        0        0         0         0         0  \n",
       "1        0        0        0        0        0         0         0         0  \n",
       "2        0        0        0        0        0         0         0         0  \n",
       "3        0        0        0        0        0         0         0         0  \n",
       "4        0        0        0        0        0         0         0         0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target and independent variables\n",
    "y = df_train['Sales_x']\n",
    "\n",
    "df_train = df_train.drop([\"Sales_x\",  \"Customers_x\"],axis=1)\n",
    "\n",
    "id_order = df_test['Id']\n",
    "\n",
    "df_test = df_test.drop([\"Id\"],axis=1)\n",
    "\n",
    "df_train = df_train.rename(index=str, columns={\"Sales_y\": \"Sales\", \"Customers_y\": \"Customers\"})\n",
    "\n",
    "df_test = df_test[df_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'Promo', 'SchoolHoliday', 'wom', 'CompetitionDistance',\n",
       "       'Promo2', 'prev_wom', 'Sales', 'Customers', 'DayOfWeek_1',\n",
       "       'DayOfWeek_2', 'DayOfWeek_3', 'DayOfWeek_4', 'DayOfWeek_5',\n",
       "       'DayOfWeek_6', 'DayOfWeek_7', 'StateHoliday_0', 'StateHoliday_1',\n",
       "       'StateHoliday_2', 'StateHoliday_3', 'StoreType_1', 'StoreType_2',\n",
       "       'StoreType_3', 'StoreType_4', 'Assortment_1', 'Assortment_2',\n",
       "       'Assortment_3', 'Month_1', 'Month_2', 'Month_3', 'Month_4', 'Month_5',\n",
       "       'Month_6', 'Month_7', 'Month_8', 'Month_9', 'Month_10', 'Month_11',\n",
       "       'Month_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'Promo', 'SchoolHoliday', 'wom', 'CompetitionDistance',\n",
       "       'Promo2', 'prev_wom', 'Sales', 'Customers', 'DayOfWeek_1',\n",
       "       'DayOfWeek_2', 'DayOfWeek_3', 'DayOfWeek_4', 'DayOfWeek_5',\n",
       "       'DayOfWeek_6', 'DayOfWeek_7', 'StateHoliday_0', 'StateHoliday_1',\n",
       "       'StateHoliday_2', 'StateHoliday_3', 'StoreType_1', 'StoreType_2',\n",
       "       'StoreType_3', 'StoreType_4', 'Assortment_1', 'Assortment_2',\n",
       "       'Assortment_3', 'Month_1', 'Month_2', 'Month_3', 'Month_4', 'Month_5',\n",
       "       'Month_6', 'Month_7', 'Month_8', 'Month_9', 'Month_10', 'Month_11',\n",
       "       'Month_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test Train Split and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train, y, test_size=0.05, \\\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear/Ridge/Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = linear_model.LinearRegression()\n",
    "d_tree = lin_reg\n",
    "d_tree.fit(X_train_std, y_train)\n",
    "y_pred_lin = d_tree.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8369841880716797, 0.24077248127641881)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(r2_score(y_test,y_pred_lin), rmspe(y_pred_lin,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = linear_model.Ridge()\n",
    "lasso_reg = linear_model.Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg.fit(X_train_std, y_train)\n",
    "lasso_reg.fit(X_train_std, y_train)\n",
    "y_pred_ridge = ridge_reg.predict(X_test_std)\n",
    "y_pred_lasso = lasso_reg.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8369870338392521, 0.24083345894516156)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(r2_score(y_test,y_pred_ridge), rmspe(y_pred_ridge,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8369680296131354, 0.24060942401659802)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(r2_score(y_test,y_pred_lasso), rmspe(y_pred_lasso,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tree = DecisionTreeRegressor()\n",
    "d_tree.fit(X_train, y_train)\n",
    "y_pred_tree = d_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8424290662502762, 0.22871736658341935)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(r2_score(y_test,y_pred_tree), rmspe(y_pred_tree,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_st = neighbors.KNeighborsRegressor(n_neighbors=5)\n",
    "knn_st.fit(X_train_std, y_train)\n",
    "y_pred_knnst = knn_st.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(r2_score(y_test,y_pred_knnst), rmspe(y_pred_knnst,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestRegressor(random_state=123) \n",
    "clf_rf.fit(X_train_std, y_train)\n",
    "y_pred_rf = clf_rf.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8979439369248127, 0.20233909101300013)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(r2_score(y_test,y_pred_rf), rmspe(y_pred_rf,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(random_state=123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.fit(X_train_std, y_train)\n",
    "y_pred_gb = gb.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8859208211335522, 0.20921159073209736)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(r2_score(y_test,y_pred_gb), rmspe(y_pred_gb,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequental Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "\n",
    "model = Sequential()\n",
    "input_dim = X_train_std.shape[1]\n",
    "\n",
    "def r2_keras(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAE1CAYAAABqRtBXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmYHNV57/Hv28ss2nesDSRAxkJCSEII5YLZDQJsIA5g4YXlYssmdrzETgBfOwJsJ+TGwZgkgAFjJIcACjZG9mUTGIxJxCKxCISIJUBIg0D7vsxMd7/3jzo90xpm6S6NmBH1+zxPP9196lSdU9U189Y5darK3B0RERFpX6qrKyAiIrI/UMAUEREpgwKmiIhIGRQwRUREyqCAKSIiUgYFTBERkTIoYIp0M2Z2tZn9e1fXoyNm9mUzu6GL6/BDM1tvZu99wOXeYmbf74TlnG1m93RGnWTfU8CUTmNmK8yswcwGtUh/yczczEZ1Tc2ks5lZFfA94J/2YRluZoe2M30k8G3gcHf/yD6sxyVm9nRpmrt/xd1/sLfLdvd5wHgzm7C3y5J9TwFTOttbwIXFL2Z2BFDbddXpWmaW6U5lx6mPmaVbST4HeN3d34lTt05yELDB3dd2YR06w93AzK6uhHRMAVM62y+Bi0q+XwzMKc1gZtVm9mMzW2lma0L3Vm2Y1t/Mfmdm68xsU/g8omTeJ83sB2b2X2a2zcwebdmiLck7KMy/2cw2mtkfzSwVpk0ysxfCMu41s3vM7Idh2vtaFKWtHTM7y8xeNLOtZrbKzK4uyTcq5L3MzFYCvw/p08zsv0NdXjazE0vmGW1mfwh1mQ+0uj4l+T8ZWu2bwzInlExbYWZXmNliYIeZZdpIGxu25WYzW2JmZ5cs404zu9nMHjSzHcBJrVTjDOAPLep1XMk6rjKzS0J6XzObE37Tt83seyW/w6Fh3beErtV7Q/pTYbEvm9l2M/tMi7JOBeYDw8L0O83sRDOra5FvRchb7OqeG+qyLaz3lJK8I83s16GeG8zsX81sLHAL8GehnM0l2+iHJfN+ycyWh/1snpkNK5nmZvYVM1sW9ul/MzMrqeaTwFmtbGPpbtxdL7065QWsAE4F/gcYC6SBVUQtAQdGhXw3APOAAUBv4LfAP4RpA4G/AHqEaf8J/KakjCeBN4CPErVcnwSua6M+/0D0zy4bXh8HDKgC3ga+FdLPAxqBH4b5LgGebrEsBw4Nn08EjiA64JwArAHODdNGhbxzgJ6hjsOBDcCZYZ5PhO+DwzwLgOuBauB4YBvw722s02RgLXBM2L4Xh+1eXfIbvASMBGpbSwvrvBz4btgWJ4cyDwv57wS2AMeG+ta0Uo/ngfNLvh8YlnFhWP5AYGKYNgd4IPyeo4A/AZeFaXcD/6dYDnBca9u8jW1xIlDX1vfSfTJ8vhrYHX6HNNH+8UyYlgZeBn4SfremurSxP9xJ8/5yMrA+/DbVwL8AT7VYj98B/cJ2WgdML5k+IOTp09V/w3q1/1ILU/aFYivzE8DrQFO3XTiy/hLwLXff6O7bgL8HZgC4+wZ3/5W77wzTfgSc0GL5v3D3P7n7LmAuMLGNejQCQ4GD3L3R3f/o0X+oaUT/1G8I6fcRBYCyuPuT7v6KuxfcfTHRP/2Wdbza3XeEOn4eeNDdHwzzzAcWAmea2YHA0cD33b3e3Z8iOoBoy5eAn7n7s+6ed/fZQH1Yp6Ib3X1VKLu1tGlAL6IDjQZ3/z3RP/QLS/I/4O7/Feq7u5V69CMKkEWfAx5z97vDNt3g7i9Z1J37GeAqd9/m7iuAfwa+EOZrJDqgGubuu919j5b9PvB0+B3yRPvpkSF9KjAM+Jvwu1VSl88Bd7j7C+5eD1xF1CIdVZLnOnff7O4rgSfYc58tbsd+8VZJPigKmLIv/BL4LNGR+ZwW0wYTtR4Xha67zcDDIR0z62FmPwtdd1uBp4B+tud5tNIRkTuJ/vm35p+IWlKPmtmbZnZlSB8GvBOCZ9Hb5a6cmR1jZk+ErrstwFd4fzfqqpLPBwHnF9c3rPNxRMF8GLDJ3XeUWZeDgG+3WNbIsJzWym4tbRiwyt0LLcoc3sEySm0iajEWjSRq+bc0iOYWfWtl/S1Rq/+50EX6vzsod2+13HdqLDqvOxJ4291zMZY5jJL1c/ftRD0IpduzvX22uB03xyhbPkAKmNLp3P1tosE/ZwK/bjF5PbALGOfu/cKrr7sX/4F8GzgMOMbd+xB1UUL0T7XSemxz92+7+8HAp4C/NrNTgHeB4S3OIx1Y8nkHUVCPCjZrOQLzP4i6lEe6e1+ibt+W9SsNxquAX5asbz937+nu14W69Deznm3UpaVVwI9aLKuHu9/dRtmtpa0GRhbPI5aU+U4b+VuzmKhbvLReh7SSbz3Nrcj3leXu77n7l9x9GPBl4CZrZ2RsB1r+bmnCgVgZVgEHWuuDojraFqspWb/wWw5kz+3ZnrHACnffWmZ+6SIKmLKvXAac3KLlRGjV3Ab8xMyGAJjZcDM7PWTpTRRQN5vZAGBW3AqEwTGHhsC4FciH1wIgB3w9DID5NFGXXNHLwDgzm2hmNUTnvkr1Bja6+24zm0rUmm7PvwOfMrPTzSxtZjVhgMqIcHCxELjGzKrM7Dii4N6W24CvhFaumVlPiwYh9W5nnpaeJQouf2tmWYsGIH0KqOR6wAfZsxv6LuBUM7sgbNOBZjYxdH3OBX5kZr3N7CDgr4m2CWZ2vjUP6tpEFJzy4fsa4OAK6vQnohbjWWaWJbrspbrMeZ8jOni5LmzTGjM7tqQeIyy6lKY1/wFcGvaXaqJTDM+G7udynAA8VGZe6UIKmLJPuPsb7r6wjclXEHWVPhO6XR8jalVCNCColqhl8gxRd21cY8KytxMFyZvC+ccG4NNEXcabiM6xNbWE3f1PwLVh3mVAy3NZfwlca2bbgL8jCghtcvdVRJdhfJdowMcq4G9o/vv7LNEgno1EBwgtu7FLl7WQ6Dzmv4a6Lw/rUbaw/mcTjXRdD9wEXOTur1ewmN8CHyuOBg3n5s4k6iHYSDTIqHh+8K+IAvSbRNvyP4A7wrSjgWfNbDtRq/0b7v5WmHY1MDt0PV9QxnptIfptbidq3e0A6tqdqXnePNFBw6HAyjBfcWTu74ElwHtmtr6VeR8Hvg/8iijoHkI4J1+mC4GfVZBfuojteRpHJJnM7E6iEZbf6+q67C/MbCbRTQO+2dV12V+Z2aeAL7h7hwcE0vUUMEVQwBSRjqlLVkREpAxqYYqIiJRBLUwREZEydNmNoT9ogwYN8lGjRnV1NUREpIssWrRovbuXe23u+yQmYI4aNYqFC9u6ykFERD7szKzsO3q1Rl2yIiIiZVDAFBERKYMCpoiISBkUMEVERMqggCkiIlIGBUwREZEyKGCKiIiUoayAaWb9zOw+M3vdzJaa2Z+Z2QAzm29my8J7/5DXzOxGM1tuZovNbHLJci4O+ZeZ2cUl6UeZ2SthnhuLD/aNU4aIiMi+UG4L86fAw+7+MaJn3C0FrgQed/cxwOPhO0TP2BsTXjOBmyEKfkTP+juG6GG9s4oBMOSZWTLf9JBeURkiIiL7SocB08z6AMcDP4fo4bPuvpnogbizQ7bZwLnh8znAHI88A/Qzs6HA6cB8d9/o7puA+cD0MK2Puy/w6E7wc1osq5Iy2rR87faOVlVERKRN5bQwDyZ6SvwvzOxFM7vdzHoCB7j7uwDhfUjIP5zoifJFdSGtvfS6VtKJUUabCnoqi4iI7IVyAmYGmAzc7O6TgB00d422xlpJ8xjp7SlrHjObaWYLzWxhLpfvYJEiIiJtKydg1hE9if7Z8P0+ogC6ptgNGt7XluQfWTL/CGB1B+kjWkknRhl7cPdb3X2Ku09JpdNlrKqIiEjrOgyY7v4esMrMDgtJpwCvAfOA4kjXi4EHwud5wEVhJOs0YEvoTn0EOM3M+ofBPqcBj4Rp28xsWhgde1GLZVVSRnvr0dGqioiItKncx3v9FXCXmVUBbwKXEgXbuWZ2GbASOD/kfRA4E1gO7Ax5cfeNZvYD4PmQ71p33xg+Xw7cCdQCD4UXwHWVlNEehUsREdkblpSWV+2wj/qu1X/q6mqIiEgXMbNF7j4l7vy604+IiEgZEhMwk9KSFhGRfSM5AbOrKyAiIvu1xARMgHxBYVNEROJJVMBszBe6ugoiIrKfSlTAzKmFKSIiMSUrYKqFKSIiMSUqYDbm1cIUEZF4EhUwNehHRETiSlTA1KAfERGJK1EBU4N+REQkrmQFTLUwRUQkpkQFTA36ERGRuBIVMHMFtTBFRCSeRAVMtTBFRCSuRAVMncMUEZG4khUwNUpWRERiUsAUEREpQ7ICprpkRUQkpkQFTA36ERGRuBIVMHVZiYiIxJWsgKkWpoiIxJSogKmbr4uISFyJCpgaJSsiInElK2CqhSkiIjElK2CqhSkiIjElK2Bq0I+IiMSUqIDZqMtKREQkpkQFTLUwRUQkroQFTLUwRUQknsQETAMaNehHRERiSkzAxNTCFBGR+BITMA3TzddFRCS25ARM083XRUQkvuQETCCvc5giIhJTcgKmqUtWRETiKytgmtkKM3vFzF4ys4UhbYCZzTezZeG9f0g3M7vRzJab2WIzm1yynItD/mVmdnFJ+lFh+cvDvBa3jDbXAQ36ERGR+CppYZ7k7hPdfUr4fiXwuLuPAR4P3wHOAMaE10zgZoiCHzALOAaYCswqBsCQZ2bJfNPjlNEeM11WIiIi8e1Nl+w5wOzweTZwbkn6HI88A/Qzs6HA6cB8d9/o7puA+cD0MK2Puy9wdwfmtFhWJWW0yTC1MEVEJLZyA6YDj5rZIjObGdIOcPd3AcL7kJA+HFhVMm9dSGsvva6V9Dhl7MHMZprZQjNbmMvndGs8ERGJLVNmvmPdfbWZDQHmm9nr7eS1VtI8Rnp7yprH3W8FbgXod+DHXF2yIiISV1ktTHdfHd7XAvcTnYNcU+wGDe9rQ/Y6YGTJ7COA1R2kj2glnRhltMl0px8REdkLHQZMM+tpZr2Ln4HTgFeBeUBxpOvFwAPh8zzgojCSdRqwJXSnPgKcZmb9w2Cf04BHwrRtZjYtjI69qMWyKimj7fXA9ABpERGJrZwu2QOA+8OVHhngP9z9YTN7HphrZpcBK4HzQ/4HgTOB5cBO4FIAd99oZj8Ang/5rnX3jeHz5cCdQC3wUHgBXFdJGe1RC1NERPaGRQNTP/wGjRrr/+s7tzHva8d1dVVERKQLmNmikksjK6Y7/YiIiJQhQQFTXbIiIhJfYgImoEE/IiISW2ICphk0qoUpIiIxJSdgYrrTj4iIxJacgGnqkhURkfiSEzCBXEFdsiIiEk9yAqapS1ZEROJLTsBEg35ERCS+xARMdA5TRET2QmICpgH5gpOUWwGKiEjnSk7AjG4er9vjiYhILMkJmOFdI2VFRCSO5ATMEDHVwhQRkTiSEzDDe14Df0REJIbkBMzQxNQTS0REJI7kBMzw3qgWpoiIxJCYgFmMmGphiohIHIkJmIYuKxERkfiSEzCLLUxdViIiIjEkJ2CGd92AXURE4khOwGy6DlMtTBERqVxyAmZoY+o6TBERiSMxARPd6UdERPZCYgKmBv2IiMjeSE7ApHinH7UwRUSkcskJmBr0IyIieyE5ATO85zToR0REYkhOwGx6gLRamCIiUrnkBMzwrnOYIiISR2ICZjFi6jpMERGJIzEBs+nm67qsREREYkhOwGx6vJdamCIiUrnkBMzwrkE/IiISR3ICZtOdftTCFBGRypUdMM0sbWYvmtnvwvfRZvasmS0zs3vNrCqkV4fvy8P0USXLuCqk/4+ZnV6SPj2kLTezK0vSKy6jzfo33elHLUwREalcJS3MbwBLS77/I/ATdx8DbAIuC+mXAZvc/VDgJyEfZnY4MAMYB0wHbgpBOA38G3AGcDhwYchbcRntMd18XURE9kJZAdPMRgBnAbeH7wacDNwXsswGzg2fzwnfCdNPCfnPAe5x93p3fwtYDkwNr+Xu/qa7NwD3AOfELKP9lTXdfF1EROIpt4V5A/C3QDHaDAQ2u3sufK8DhofPw4FVAGH6lpC/Kb3FPG2lxymjXZl0SqNkRUQklg4Dppl9Eljr7otKk1vJ6h1M66z0jspvYmYzzWyhmS1ct24d2ZRp0I+IiMRSTgvzWOBsM1tB1F16MlGLs5+ZZUKeEcDq8LkOGAkQpvcFNpamt5inrfT1McrYg7vf6u5T3H3K4MGDQwtTXbIiIlK5DgOmu1/l7iPcfRTRoJ3fu/vngCeA80K2i4EHwud54Tth+u/d3UP6jDDCdTQwBngOeB4YE0bEVoUy5oV5Ki2jXdm00agWpoiIxJDpOEubrgDuMbMfAi8CPw/pPwd+aWbLiVp9MwDcfYmZzQVeA3LAV909D2BmXwMeAdLAHe6+JE4ZHa5sSi1MERGJx8pomH0oTJkyxWvO/79MHTWA6z8zsaurIyIiHzAzW+TuU+LOn5g7/QBk0yl1yYqISCx70yW730mnTF2yItKtNDY2UldXx+7du7u6Kh8aNTU1jBgxgmw226nLTVTAzKRMd/oRkW6lrq6O3r17M2rUKMq4/4p0wN3ZsGEDdXV1jB49ulOXnbgu2bzu9CMi3cju3bsZOHCggmUnMTMGDhy4T1rsiQqYmbRuXCAi3Y+CZefaV9szUQEzm0rpeZgiIhJLogJmJm26l6yISAubN2/mpptuqni+M888k82bN7eb5+/+7u947LHH4latW0lYwNRlJSIiLbUVMPP5fLvzPfjgg/Tr16/dPNdeey2nnnrqXtWvu0hUwMzqshIRkfe58soreeONN5g4cSJHH300J510Ep/97Gc54ogjADj33HM56qijGDduHLfeemvTfKNGjWL9+vWsWLGCsWPH8qUvfYlx48Zx2mmnsWvXLgAuueQS7rvvvqb8s2bNYvLkyRxxxBG8/vrrAKxbt45PfOITTJ48mS9/+cscdNBBrF+//gPeCh1L1GUl0XWYamGKSPd0zW+X8NrqrZ26zMOH9WHWp8a1m+e6667j1Vdf5aWXXuLJJ5/krLPO4tVXX226LOOOO+5gwIAB7Nq1i6OPPpq/+Iu/YODAPZ+ouGzZMu6++25uu+02LrjgAn71q1/x+c9//n1lDRo0iBdeeIGbbrqJH//4x9x+++1cc801nHzyyVx11VU8/PDDewTl7iRZLcx0ikZdViIi0q6pU6fucQ3jjTfeyJFHHsm0adNYtWoVy5Yte988o0ePZuLE6LajRx11FCtWrGh12Z/+9Kffl+fpp59mxozoluDTp0+nf//+nbg2nSdRLUwN+hGR7qyjluAHpWfPnk2fn3zySR577DEWLFhAjx49OPHEE1u9xrG6urrpczqdbuqSbStfOp0ml8sB0c0G9geJamFmUinyGvQjIrKH3r17s23btlanbdmyhf79+9OjRw9ef/11nnnmmU4v/7jjjmPu3LkAPProo2zatKnTy+gMiWphZtOm6zBFRFoYOHAgxx57LOPHj6e2tpYDDjigadr06dO55ZZbmDBhAocddhjTpk3r9PJnzZrFhRdeyL333ssJJ5zA0KFD6d27d6eXs7cS9Xiv6d/7BQ++8h4vfP8TXV0dEREAli5dytixY7u6Gl2qvr6edDpNJpNhwYIFXH755bz00kt7tczWtuvePt4rUS3MjO70IyLS7axcuZILLriAQqFAVVUVt912W1dXqVWJCphZDfoREel2xowZw4svvtjV1ehQsgb9pFPkdFmJiIjEkKyAGZ6HmZTztiIi0nkSFjCj1dWlJSIiUqlkBcx09Iw0PRNTREQqlaiAmVXAFBHZa7169QJg9erVnHfeea3mOfHEE1m4cGG7y7nhhhvYuXNn0/dyHhfWlRIVMItdsnpiiYjI3hs2bFjTk0jiaBkwy3lcWFdKVMAstjAbdWmJiEiTK664Yo/nYV599dVcc801nHLKKU2P4nrggQfeN9+KFSsYP348ALt27WLGjBlMmDCBz3zmM3vcS/byyy9nypQpjBs3jlmzZgHRDd1Xr17NSSedxEknnQQ0Py4M4Prrr2f8+PGMHz+eG264oam8th4j9kFI1HWYmXRoYerSEhHpjh66Et57pXOX+ZEj4Izr2s0yY8YMvvnNb/KXf/mXAMydO5eHH36Yb33rW/Tp04f169czbdo0zj77bMys1WXcfPPN9OjRg8WLF7N48WImT57cNO1HP/oRAwYMIJ/Pc8opp7B48WK+/vWvc/311/PEE08waNCgPZa1aNEifvGLX/Dss8/i7hxzzDGccMIJ9O/fv+zHiO0LiWphZlLhHKZamCIiTSZNmsTatWtZvXo1L7/8Mv3792fo0KF897vfZcKECZx66qm88847rFmzps1lPPXUU02Ba8KECUyYMKFp2ty5c5k8eTKTJk1iyZIlvPbaa+3W5+mnn+bP//zP6dmzJ7169eLTn/40f/zjH4HyHyO2LySshVnsklULU0S6oQ5agvvSeeedx3333cd7773HjBkzuOuuu1i3bh2LFi0im80yatSoVh/rVaq11udbb73Fj3/8Y55//nn69+/PJZdc0uFy2rtWvtzHiO0LCWthFrtk1cIUESk1Y8YM7rnnHu677z7OO+88tmzZwpAhQ8hmszzxxBO8/fbb7c5//PHHc9dddwHw6quvsnjxYgC2bt1Kz5496du3L2vWrOGhhx5qmqetx4odf/zx/OY3v2Hnzp3s2LGD+++/n49//OOduLbxJKqF2XRZibpkRUT2MG7cOLZt28bw4cMZOnQon/vc5/jUpz7FlClTmDhxIh/72Mfanf/yyy/n0ksvZcKECUycOJGpU6cCcOSRRzJp0iTGjRvHwQcfzLHHHts0z8yZMznjjDMYOnQoTzzxRFP65MmTueSSS5qW8cUvfpFJkyZ9oN2vrUnU472um/P/+OKchcz72rFMGNF9hy6LSHLo8V77xr54vFeyumR1WYmIiMSUqICZTevGBSIiEk+iAmbTZSUa9CMi3UhSTo19UPbV9kxWwAwtTF1WIiLdRU1NDRs2bFDQ7CTuzoYNG6ipqen0ZWuUrIhIFxoxYgR1dXWsW7euq6vyoVFTU8OIESM6fbmJCpjppi5ZtTBFpHvIZrOMHj26q6shZeiwS9bMaszsOTN72cyWmNk1IX20mT1rZsvM7F4zqwrp1eH78jB9VMmyrgrp/2Nmp5ekTw9py83sypL0istoT7apS1YtTBERqUw55zDrgZPd/UhgIjDdzKYB/wj8xN3HAJuAy0L+y4BN7n4o8JOQDzM7HJgBjAOmAzeZWdrM0sC/AWcAhwMXhrxUWkZHioN+8hr0IyIiFeowYHpke/iaDS8HTgaKD0KbDZwbPp8TvhOmn2LRDQbPAe5x93p3fwtYDkwNr+Xu/qa7NwD3AOeEeSoto11ZDfoREZGYyholG1qCLwFrgfnAG8Bmd8+FLHXA8PB5OLAKIEzfAgwsTW8xT1vpA2OU0bLeM81soZktXLduXdONC3RZiYiIVKqsgOnueXefCIwgahG2dh+nYhRqraXnnZjeXhl7Jrjf6u5T3H3K4MGDm2++rhamiIhUqKLrMN19M/AkMA3oZ2bFUbYjgNXhcx0wEiBM7wtsLE1vMU9b6etjlNGurG6NJyIiMZUzSnawmfULn2uBU4GlwBPAeSHbxcAD4fO88J0w/fceXZE7D5gRRriOBsYAzwHPA2PCiNgqooFB88I8lZbRruKNC3RZiYiIVKqc6zCHArPDaNYUMNfdf2dmrwH3mNkPgReBn4f8Pwd+aWbLiVp9MwDcfYmZzQVeA3LAV909D2BmXwMeAdLAHe6+JCzrikrK6HBlU2phiohIPB0GTHdfDExqJf1NovOZLdN3A+e3sawfAT9qJf1B4MHOKKM9TfeSVcAUEZEKJepesumm6zDVJSsiIpVJVMA0M7Jpo1GXlYiISIUSFTABMqmULisREZGKJS9gpk2DfkREpGKJC5jZdEqXlYiISMUSFzAzKdMoWRERqVjiAmY2nVKXrIiIVCxxATOdMnXJiohIxRIXMDNpdcmKiEjlEhcwsykN+hERkcolLmCqhSkiInEkMGCmdKcfERGpWOICZjZlutOPiIhULHEBU12yIiISR+ICZjadolGDfkREpEKJC5hp3elHRERiSFzAzKRSNOocpoiIVChxATObNvIaJSsiIhVKXMDMpFPkFDBFRKRCiQuY2ZSpS1ZERCqWuICpy0pERCSOBAZM3UtWREQql7iAGXXJqoUpIiKVSVzAzKRTujWeiIhULHkBM2W6+bqIiFQseQFT12GKiEgMyQuYqRT5guOuoCkiIuVLXMDMpg1AA39ERKQiiQuYmXS0yrq0REREKpG8gJlSC1NERCqXuICZLbYwdWmJiIhUIHEBMxPOYeoG7CIiUonkBcymLlm1MEVEpHwJDJjFLlm1MEVEpHzJC5jqkhURkRg6DJhmNtLMnjCzpWa2xMy+EdIHmNl8M1sW3vuHdDOzG81suZktNrPJJcu6OORfZmYXl6QfZWavhHluNDOLW0ZHsrqsREREYiinhZkDvu3uY4FpwFfN7HDgSuBxdx8DPB6+A5wBjAmvmcDNEAU/YBZwDDAVmFUMgCHPzJL5pof0isooR/EcprpkRUSkEh0GTHd/191fCJ+3AUuB4cA5wOyQbTZwbvh8DjDHI88A/cxsKHA6MN/dN7r7JmA+MD1M6+PuCzy6X92cFsuqpIwOFVuYGvQjIiKVqOgcppmNAiYBzwIHuPu7EAVVYEjINhxYVTJbXUhrL72ulXRilNEhncMUEZE4yg6YZtYL+BXwTXff2l7WVtI8Rnq71SlnHjObaWYLzWzhunXrgOZRsmphiohIJcoKmGaWJQqWd7n7r0PymmI3aHhfG9LrgJEls48AVneQPqKV9Dhl7MHdb3X3Ke4+ZfDgwUDzzdd1DlNERCpRzihZA34OLHX360smzQOKI10vBh4oSb8ojGSdBmwJ3amPAKeZWf8w2Oc04JEwbZuZTQtlXdRiWZWU0aF0cdCPRsmKiEgFMmXkORb4AvCKmb0U0r4LXAfMNbPLgJXA+WHag8CZwHJgJ3ApgLtvNLMfAM+HfNdZf906AAASo0lEQVS6+8bw+XLgTqAWeCi8qLSMcjTfS1YtTBERKV+HAdPdn6b1c4YAp7SS34GvtrGsO4A7WklfCIxvJX1DpWV0RIN+REQkjuTd6UeDfkREJIbEBUwN+hERkTgSFzAzujWeiIjEkLiAmW16vJdamCIiUr7EBcymFqbOYYqISAUSFzCbr8NUC1NERMqXuIBZHPSjLlkREalE4gJm8bKSvAb9iIhIBRIXMNXCFBGROBIXMM2MdMp0WYmIiFQkcQETIJMy3bhAREQqksiAmU2n1CUrIiIVSWTAzKTVJSsiIpVJZsBMmVqYIiJSkYQGzJTu9CMiIhVJTsDc9l7Tx0zayOtOPyIiUoFkBcw1S4Aw6EcBU0REKpCcgJlKw//7DriHy0rUJSsiIuVLTsDsMxRW/je88p9kdFmJiIhUKDkBs8cgGDYJHv0efWwXO+pzXV0jERHZjyQnYAKc+c+wfS1/XXU/C97cwGOvrenqGomIyH4iWQFzxFEw+QtMXTuX04ds5m/ue5k1W3d3da1ERGQ/kKyACXDK1VhVL35afQupxh18856XdImJiIh0KHkBs+dA+POfUbN+CQ8OuYkX3nyXW/7wRlfXSkREurnkBUyAw6bDuTdzwIbn+M9Bt/HT+Ut55s0NXV0rERHpxjJdXYEuc+RnoH4rEx78Dv/SI8vnbze+csIY/uqUQ6nOpLu6diIi0s0ks4VZNPVLcNL3OD33JL/tfyP/9eRDfPLGp3lx5aaurpmIiHQzyW1hFh3/HcjWMvapf+L+6md5Yds4fnrLJ6kdexpnTxzOSR8bQk1WLU4RkaQz92SMEJ0yZYovXLiw7Qz12+GF2RT++19IbXuXDfRlQX4si2w82UNP4ODDJnD48H589IDeCqAiIvshM1vk7lNiz6+A2UKuAV57gMKy+TS+8Qeqd0ZPOdntWd7yj7CCoWypHYn1GEymV39qeg+kZ99B9Orbn959B9J/wCD6DxhINlu1j9dIREQqsbcBU12yLWWqYML5pCacT7U7bHyTwoqnqa9bwoD3/sSQTW/Sd/ciMvV5aONUZ85T1Nlg3ssMZ2PNSHb0GkVh0EepGTqOQR8ZyeghvRjSu+aDXS8REdkrCpjtMYOBh5AaeAh9j4K+xfRCARq2wa5N1G/byKaN69i+ZSO7tm1i9/ZNFLavo3bb2wzetZJxOx6ldvsueA94FbZ4D5b6Qfw2M57NBxxDz0P+jCNHD2XyQf00OldEpBtTl+y+5g7b3qNhzVK2rXyVhveWklnzEgO3vk6KAg2e5mU/hBcYy5YhUxk49uMc9dGDOHxoH6oyyR7ELCLSmXQOs0xdFjDbsnsLrHyW+uV/YPfyP9Jr46ukyZN3Y4mPYhFjWTfgaKoPOZYjxoziqIMG0Lc229W1FhHZbylglqnbBcyWGnZA3fPs+FMUQPtueJmMNwDwVuEAXveDWNdzDNlhE+g34jAGjxjDQUMHM6hXFWbWxZUXEen+FDDL1O0DZku5enjnBRrffJqtby0kvXYJ/Xav2iPLRu/FuwxhffVwdvQ6iHy/Q6j+yGEMHjOFjw4bSM9qnaIWESna5wHTzO4APgmsdffxIW0AcC8wClgBXODumyxq6vwUOBPYCVzi7i+EeS4GvhcW+0N3nx3SjwLuBGqBB4FvuLvHKaM9+13AbE39dvJrXmPzO39iy3tv0rj+bdJbV9Jn1yoG5taQpgDALq9iYeGjvF5zJFuGTGXs5I9z8hGjqK3SoCIRSa4PImAeD2wH5pQEzP8LbHT368zsSqC/u19hZmcCf0UUzI4Bfurux4TgtxCYAjiwCDgqBMDngG8AzxAFzBvd/aFKy+hoRT8UAbM9uQbyG99i04qX2bnsj/RYvYBBO5YBkHfjDUawpf84+o2eTP9hB9P/I6NJ9x0OPQdDWi1REfnw2+fXYbr7U2Y2qkXyOcCJ4fNs4EngipA+x6Mo/IyZ9TOzoSHvfHffGCo9H5huZk8Cfdx9QUifA5wLPFRpGe7+bmWr/iGTqSI95DAGDTkMpl4Qpe3cSP7tBaxeuoD8m89z8KYFDNz8MLy456wNVk0u3YN8tgde1YdCj0Gkeg0i03sIVb0HkqntA9W9o1emBtJZSGUhXQWpDKTS4T0TXceaqYVMdZTXSkb6WiqaV+dcRWQ/FLdpcUAxQLn7u2Y2JKQPB0pPtNWFtPbS61pJj1PG+wKmmc0EZgIceOCBFa7ih0CPAaTHnsXIsWcBsLshx3PL3mDDu2+zfe3bNGysgx1rKdTvwOp3UFu/m77sYOCmdxnI6wyyrWSsvlOr5Bj5dA35dC2FdBXmeVJewDwPOG5R8HVL45bac0CTpfBUFlJpPJUBUs2x1x0M9gjFqTSksngqg6eymKUglY7ezaCQwzwH+Rx4ATLVeLq6+aAAx7wQLdMLTWvQVB6O4RgWHQyk0lH90lnAMLwpv0FUplmY4tH1vF5oWraZNecrHnBkaqIDE89DIby8EA46rPkdb6oTWPNBTKhL8/RiPVLhYMYg3wC53dC4C/L10cFQpqa5DsX19kK0jEJjVI98Y9N2I1vbXNc2D4iibd5UVq4+Wm7pQVchF6Xndkd33cpUQVUvyPaAqh5RndvsFfNontzuaBmFXPN6plKhnHCgl86EA77wexXr7Xv+JhR/W7Oo3NLpud3QuLN5XdLZ5t8sU9283YvLafpNq6P1bdwNuV3Re6Fxz7JoUZewL0d1zUZp+cZoHfON4WC1uPyq5t+2+HuX7iuWCtsgrHemKvx21dEyLBWtU+OO6N09HDD3gqre4bcO61Ap9/IPmEv3126is/viWlszj5Eep4z3J7rfCtwKUZdsB8v90KupyjB13GEw7rD3TcsXnA3b61m/vYHNOxt4ZWcjG3c2sH3HTuq3b6F+52Yad24l37CbXGMDuVwD+cZ6Cvkcns9RyDfi+UbShQaqaKSGBqpp3OPHSlGg2hqozTU0Tc+TIk+KHNEfX5oCafJkKJC2wh51TFEgQ540BbJEAXZPpaU5aQpkaCDLLjKWI4WTwjEKpHDypGkkTd7TOJC1zVTTSDWNZMk1hcNCePewfC8pz0NYTOFkyJMhR9byzbVwa9rRzbxpLscoeLEmNC0bIGUe6hFtoypyFEiRIxXWPgqsqXDOurg8wnIsrHuafNhOxS1SMt2a1yLvRj1V7KaKRrKkLb9H2UWFsK45MuTCditgTb93ysr/E2sgQwNVFDDSYa0y5MiFX6yBLI1kyJKjlt30ZHfZy24kQyMZcmQwCqQpkArv2ZL16Sx5UjSQJUN+nyy/uypYmkKqKux7YQ90x1MZ8qkqCukqCqks6UIj6dxO0vldpAuN5FNZ8pme5DI9yKdr8XAQCWCeJ53bRSa3k3RuBynPkU9Xk0/Xks/URge+hTzmOSwcOOYzPclnailkegBGyhuxfAOpQiNuKTxTQyFdTSG993dXixsw1xS7QUOX69qQXgeMLMk3Algd0k9skf5kSB/RSv44ZcheSKeMIX1qGNJn73eqQsHJFZxcoUC+4OSL3/NRWi7vNOYLNOadgkfT8+4UCo6H+R0ouFMoEE0rTvcoPe8A0XcnHPzjFBw8LLNUcb7oxfunt1gH92jZ+UI0T2sHxsUy84W2p7k3L6u0noZFDT1CY7epftH6F5fX1IAO26O4nOJ8xeUUl1ssu3l+a6pjy+1iOClzCt4c+ItlNK1HoRC18lusYOnyozILpL2RVKGxeftB+D2K28DJYeStuXXSXuNhj/VwD5dZFaKGeVh2y9kbLUuBdLQtWonf7o55jpTnon/k5Ml4LjpAcqdgRsFTe8xqoXXdfKgFTopGq6YhVU2eDB5+Awp5Ml5POmyH5q1UIOONZL2BrDeQ8jyNqWoarJoGqyJPKjRqHfdCtM0sRdS/YaTMyXgjaY8OV/KeImdpch4dvKQ8R8YbyBQayXh903MbUxb9AI7jhbDsQoEUebLeQLqQI1VowPL1pAr1WL6BQj7PtkIV2/NZdnh0T+ye7KaX7aIXu6glOiiusuiAqukAMPwaGQpU00AVOaqskQbPspNqdlFNPVmqaaRHw256Wj217G5xmAs7vYbt1LKTanJkqM410IN6aqkna9FBVc5TFEiRpkAP200t9fRgJwY0kqaeGnL0JE2Bahqpsa1Us77tna1McQPmPOBi4Lrw/kBJ+tfM7B6iATlbQsB7BPh7M+sf8p0GXOXuG81sm5lNA54FLgL+JU4ZMddD9oFUyqhKGVUJf9yqyP4uX4gObt2jA9d8wZsOvPLhgLbgJQe6pQeKNB84eckBbkvFpOJBbekyCu7NrU9rzlc8OCweIBdK5k25U1WazyEHNDrwg8F7tT06DJhmdjdR63CQmdUBs4iC2FwzuwxYCZwfsj9INHp1OdElH5dGK+gbzewHwPMh37XFAUDA5TRfVvJQeFFpGSIi0rnSKSMd51zlh5RuXCAiIomwt5eVqM9MRESkDAqYIiIiZVDAFBERKYMCpoiISBkUMEVERMqggCkiIlIGBUwREZEyKGCKiIiUITE3LjCzdcDbXV2P/cAg6ISbLiaPtls82m7xaLvFc5i79447c2KeHOzue3cTwYQws4V7cyeMpNJ2i0fbLR5tt3jMbK9u96YuWRERkTIoYIqIiJRBAVNaurWrK7Cf0naLR9stHm23ePZquyVm0I+IiMjeUAtTRESkDAqYCWZmI83sCTNbamZLzOwbIX2Amc03s2XhvX9X17W7MbO0mb1oZr8L30eb2bNhm91rZlVdXcfuxsz6mdl9ZvZ62Of+TPtax8zsW+Hv81Uzu9vMarS/vZ+Z3WFma83s1ZK0Vvcvi9xoZsvNbLGZTS6nDAXMZMsB33b3scA04KtmdjhwJfC4u48BHg/fZU/fAJaWfP9H4Cdhm20CLuuSWnVvPwUedvePAUcSbT/ta+0ws+HA14Ep7j4eSAMz0P7WmjuB6S3S2tq/zgDGhNdM4OZyClDATDB3f9fdXwiftxH9AxsOnAPMDtlmA+d2TQ27JzMbAZwF3B6+G3AycF/Iom3Wgpn1AY4Hfg7g7g3uvhnta+XIALVmlgF6AO+i/e193P0pYGOL5Lb2r3OAOR55BuhnZkM7KkMBUwAws1HAJOBZ4AB3fxeioAoM6bqadUs3AH8LFML3gcBmd8+F73VEBx7S7GBgHfCL0JV9u5n1RPtau9z9HeDHwEqiQLkFWIT2t3K1tX8NB1aV5CtrGypgCmbWC/gV8E1339rV9enOzOyTwFp3X1Sa3EpWDT/fUwaYDNzs7pOAHaj7tUPhnNs5wGhgGNCTqDuxJe1vlYn1N6uAmXBmliUKlne5+69D8ppi90R4X9tV9euGjgXONrMVwD1EXWM3EHXpFG81OQJY3TXV67bqgDp3fzZ8v48ogGpfa9+pwFvuvs7dG4FfA/8L7W/lamv/qgNGluQraxsqYCZYOPf2c2Cpu19fMmkecHH4fDHwwAddt+7K3a9y9xHuPopo8MXv3f1zwBPAeSGbtlkL7v4esMrMDgtJpwCvoX2tIyuBaWbWI/y9Freb9rfytLV/zQMuCqNlpwFbil237dGNCxLMzI4D/gi8QvP5uO8SncecCxxI9Ad7vru3PJmeeGZ2IvAdd/+kmR1M1OIcALwIfN7d67uyft2NmU0kGihVBbwJXEp00K59rR1mdg3wGaJR7S8CXyQ636b9rYSZ3Q2cSPQklzXALOA3tLJ/hYOPfyUaVbsTuNTdO7wxuwKmiIhIGdQlKyIiUgYFTBERkTIoYIqIiJRBAVNERKQMCpgiIiJlUMAUESC6TKb49BUReT8FTBERkTIoYIrsZ8zs82b2nJm9ZGY/C8/m3G5m/2xmL5jZ42Y2OOSdaGbPhGf+3V/yPMBDzewxM3s5zHNIWHyvkmdW3hUu8BYRFDBF9itmNpbori/HuvtEIA98juim3C+4+2TgD0R3OQGYA1zh7hOI7uhUTL8L+Dd3P5Lo3qTF24JNAr4JHE70hJFj9/lKiewnMh1nEZFu5BTgKOD50PirJbqhdAG4N+T5d+DXZtYX6Ofufwjps4H/NLPewHB3vx/A3XcDhOU95+514ftLwCjg6X2/WiLdnwKmyP7FgNnuftUeiWbfb5GvvXtettfNWno/0jz6HyHSRF2yIvuXx4HzzGwIgJkNMLODiP6Wi0+v+CzwtLtvATaZ2cdD+heAP4RnntaZ2blhGdVm1uMDXQuR/ZCOHkX2I+7+mpl9D3jUzFJAI/BVogcyjzOzRcAWovOcED3S6JYQEItPCIEoeP7MzK4Nyzj/A1wNkf2SnlYi8iFgZtvdvVdX10Pkw0xdsiIiImVQC1NERKQMamGKiIiUQQFTRESkDAqYIiIiZVDAFBERKYMCpoiISBkUMEVERMrw/wFc6PsjXwaG4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x243a7fc34e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (cost function):\n",
      "training   (min: 944331.567, max: 6016067.220, cur: 944331.567)\n",
      "validation (min: 954905.620, max: 1514322.280, cur: 954905.620)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x243bf8905c0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_std, y_train, batch_size = 20, \\\n",
    "          epochs = 100,validation_split=0.2, callbacks=[PlotLossesKeras()], \\\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9015612951877684, 0.20268189708684567)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(r2_score(y_test, y_pred), rmspe(y_pred.flatten(),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR(kernel='linear')\n",
    "svr.fit(X_train_std, y_train)\n",
    "y_pred_svr = svr.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(r2_score(y_test,y_pred_svr), rmspe(y_pred_svr,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "dtc = DecisionTreeRegressor()\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "stregr = StackingRegressor(regressors=[dtc, lr], meta_regressor=rf)\n",
    "stack = stregr.fit(X_train_std, y_train)\n",
    "y_pred_stack = stack.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8413216452141783, 0.2303344162663707)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(r2_score(y_test,y_pred_stack), rmspe(y_pred_stack,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor, BaggingRegressor\n",
    "bag = BaggingRegressor()\n",
    "bag.fit(X_train_std, y_train)\n",
    "y_pred_bag = bag.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8969294364824312, 0.19702412048685583)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(r2_score(y_test,y_pred_bag), rmspe(y_pred_bag,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use log on target column y\n",
    "dtrain = xgb.DMatrix(X_train, np.log(y_train + 1))\n",
    "dvalid = xgb.DMatrix(X_test, np.log(y_test + 1))\n",
    "dtest = xgb.DMatrix(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking parameters\n",
    "params = {\"objective\": \"reg:linear\",\n",
    "          \"eta\": 0.3,\n",
    "          \"max_depth\": 7,\n",
    "          \"subsample\": 0.75,\n",
    "          \"colsample_bytree\": 0.7,\n",
    "          \"silent\": 1\n",
    "          }\n",
    "\n",
    "num_trees = 400\n",
    "\n",
    "watchlist = [(dvalid, 'eval'), (dtrain, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:5.79028\ttrain-rmse:5.78982\teval-rmspe:0.99689\ttrain-rmspe:0.996879\n",
      "Multiple eval metrics have been passed: 'train-rmspe' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmspe hasn't improved in 50 rounds.\n",
      "[1]\teval-rmse:4.05614\ttrain-rmse:4.05548\teval-rmspe:0.982052\ttrain-rmspe:0.98203\n",
      "[2]\teval-rmse:2.84244\ttrain-rmse:2.84173\teval-rmspe:0.939991\ttrain-rmspe:0.939936\n",
      "[3]\teval-rmse:1.99373\ttrain-rmse:1.99301\teval-rmspe:0.860629\ttrain-rmspe:0.860512\n",
      "[4]\teval-rmse:1.40157\ttrain-rmse:1.40086\teval-rmspe:0.748833\ttrain-rmspe:0.748594\n",
      "[5]\teval-rmse:0.987595\ttrain-rmse:0.986974\teval-rmspe:0.622089\ttrain-rmspe:0.621621\n",
      "[6]\teval-rmse:0.700776\ttrain-rmse:0.700311\teval-rmspe:0.498718\ttrain-rmspe:0.497765\n",
      "[7]\teval-rmse:0.503094\ttrain-rmse:0.502873\teval-rmspe:0.392375\ttrain-rmspe:0.390929\n",
      "[8]\teval-rmse:0.368737\ttrain-rmse:0.368789\teval-rmspe:0.309863\ttrain-rmspe:0.306175\n",
      "[9]\teval-rmse:0.279126\ttrain-rmse:0.279529\teval-rmspe:0.252062\ttrain-rmspe:0.245644\n",
      "[10]\teval-rmse:0.222374\ttrain-rmse:0.22322\teval-rmspe:0.215885\ttrain-rmspe:0.207596\n",
      "[11]\teval-rmse:0.188271\ttrain-rmse:0.189352\teval-rmspe:0.196059\ttrain-rmspe:0.186084\n",
      "[12]\teval-rmse:0.168289\ttrain-rmse:0.169557\teval-rmspe:0.186284\ttrain-rmspe:0.175152\n",
      "[13]\teval-rmse:0.157433\ttrain-rmse:0.158647\teval-rmspe:0.182903\ttrain-rmspe:0.170263\n",
      "[14]\teval-rmse:0.151598\ttrain-rmse:0.152774\teval-rmspe:0.181914\ttrain-rmspe:0.168672\n",
      "[15]\teval-rmse:0.147897\ttrain-rmse:0.148779\teval-rmspe:0.181759\ttrain-rmspe:0.168023\n",
      "[16]\teval-rmse:0.145821\ttrain-rmse:0.14657\teval-rmspe:0.181853\ttrain-rmspe:0.167531\n",
      "[17]\teval-rmse:0.144574\ttrain-rmse:0.145312\teval-rmspe:0.182097\ttrain-rmspe:0.167065\n",
      "[18]\teval-rmse:0.143437\ttrain-rmse:0.144216\teval-rmspe:0.182115\ttrain-rmspe:0.166814\n",
      "[19]\teval-rmse:0.142878\ttrain-rmse:0.143685\teval-rmspe:0.182289\ttrain-rmspe:0.16686\n",
      "[20]\teval-rmse:0.142388\ttrain-rmse:0.143122\teval-rmspe:0.182374\ttrain-rmspe:0.166678\n",
      "[21]\teval-rmse:0.142224\ttrain-rmse:0.142863\teval-rmspe:0.182715\ttrain-rmspe:0.166672\n",
      "[22]\teval-rmse:0.142021\ttrain-rmse:0.142422\teval-rmspe:0.182735\ttrain-rmspe:0.164692\n",
      "[23]\teval-rmse:0.141741\ttrain-rmse:0.142081\teval-rmspe:0.182606\ttrain-rmspe:0.16446\n",
      "[24]\teval-rmse:0.141281\ttrain-rmse:0.141473\teval-rmspe:0.182256\ttrain-rmspe:0.164476\n",
      "[25]\teval-rmse:0.141305\ttrain-rmse:0.141368\teval-rmspe:0.182481\ttrain-rmspe:0.164432\n",
      "[26]\teval-rmse:0.141156\ttrain-rmse:0.141104\teval-rmspe:0.182589\ttrain-rmspe:0.164098\n",
      "[27]\teval-rmse:0.140604\ttrain-rmse:0.140604\teval-rmspe:0.182152\ttrain-rmspe:0.163535\n",
      "[28]\teval-rmse:0.140366\ttrain-rmse:0.140317\teval-rmspe:0.182099\ttrain-rmspe:0.163018\n",
      "[29]\teval-rmse:0.140013\ttrain-rmse:0.139952\teval-rmspe:0.181714\ttrain-rmspe:0.162757\n",
      "[30]\teval-rmse:0.139896\ttrain-rmse:0.139702\teval-rmspe:0.181721\ttrain-rmspe:0.161962\n",
      "[31]\teval-rmse:0.139842\ttrain-rmse:0.139582\teval-rmspe:0.181763\ttrain-rmspe:0.161842\n",
      "[32]\teval-rmse:0.139628\ttrain-rmse:0.139356\teval-rmspe:0.181606\ttrain-rmspe:0.161547\n",
      "[33]\teval-rmse:0.139393\ttrain-rmse:0.139036\teval-rmspe:0.181322\ttrain-rmspe:0.161273\n",
      "[34]\teval-rmse:0.139338\ttrain-rmse:0.138929\teval-rmspe:0.181236\ttrain-rmspe:0.161049\n",
      "[35]\teval-rmse:0.139249\ttrain-rmse:0.138771\teval-rmspe:0.181158\ttrain-rmspe:0.160835\n",
      "[36]\teval-rmse:0.139142\ttrain-rmse:0.13859\teval-rmspe:0.180963\ttrain-rmspe:0.160643\n",
      "[37]\teval-rmse:0.139004\ttrain-rmse:0.138404\teval-rmspe:0.180814\ttrain-rmspe:0.160498\n",
      "[38]\teval-rmse:0.139004\ttrain-rmse:0.137811\teval-rmspe:0.180668\ttrain-rmspe:0.160237\n",
      "[39]\teval-rmse:0.138721\ttrain-rmse:0.137456\teval-rmspe:0.180164\ttrain-rmspe:0.159766\n",
      "[40]\teval-rmse:0.138353\ttrain-rmse:0.137046\teval-rmspe:0.179922\ttrain-rmspe:0.159406\n",
      "[41]\teval-rmse:0.138263\ttrain-rmse:0.136961\teval-rmspe:0.179709\ttrain-rmspe:0.159326\n",
      "[42]\teval-rmse:0.138192\ttrain-rmse:0.136878\teval-rmspe:0.179587\ttrain-rmspe:0.159224\n",
      "[43]\teval-rmse:0.138212\ttrain-rmse:0.136844\teval-rmspe:0.179698\ttrain-rmspe:0.159202\n",
      "[44]\teval-rmse:0.138131\ttrain-rmse:0.136638\teval-rmspe:0.17965\ttrain-rmspe:0.159074\n",
      "[45]\teval-rmse:0.13807\ttrain-rmse:0.136507\teval-rmspe:0.179765\ttrain-rmspe:0.159033\n",
      "[46]\teval-rmse:0.13789\ttrain-rmse:0.13632\teval-rmspe:0.17962\ttrain-rmspe:0.158913\n",
      "[47]\teval-rmse:0.137621\ttrain-rmse:0.136001\teval-rmspe:0.179313\ttrain-rmspe:0.158607\n",
      "[48]\teval-rmse:0.137571\ttrain-rmse:0.13594\teval-rmspe:0.179268\ttrain-rmspe:0.158577\n",
      "[49]\teval-rmse:0.137318\ttrain-rmse:0.135679\teval-rmspe:0.179057\ttrain-rmspe:0.158247\n",
      "[50]\teval-rmse:0.137194\ttrain-rmse:0.135556\teval-rmspe:0.178958\ttrain-rmspe:0.158156\n",
      "[51]\teval-rmse:0.13717\ttrain-rmse:0.135387\teval-rmspe:0.178857\ttrain-rmspe:0.158049\n",
      "[52]\teval-rmse:0.137093\ttrain-rmse:0.1353\teval-rmspe:0.178702\ttrain-rmspe:0.157994\n",
      "[53]\teval-rmse:0.137035\ttrain-rmse:0.135217\teval-rmspe:0.178766\ttrain-rmspe:0.157901\n",
      "[54]\teval-rmse:0.137005\ttrain-rmse:0.135139\teval-rmspe:0.178706\ttrain-rmspe:0.157731\n",
      "[55]\teval-rmse:0.136975\ttrain-rmse:0.134866\teval-rmspe:0.178689\ttrain-rmspe:0.15763\n",
      "[56]\teval-rmse:0.136754\ttrain-rmse:0.134555\teval-rmspe:0.178355\ttrain-rmspe:0.15737\n",
      "[57]\teval-rmse:0.1365\ttrain-rmse:0.134293\teval-rmspe:0.17819\ttrain-rmspe:0.157096\n",
      "[58]\teval-rmse:0.13638\ttrain-rmse:0.134123\teval-rmspe:0.178043\ttrain-rmspe:0.156873\n",
      "[59]\teval-rmse:0.136363\ttrain-rmse:0.134091\teval-rmspe:0.178062\ttrain-rmspe:0.15683\n",
      "[60]\teval-rmse:0.136333\ttrain-rmse:0.134017\teval-rmspe:0.178002\ttrain-rmspe:0.156705\n",
      "[61]\teval-rmse:0.136267\ttrain-rmse:0.133897\teval-rmspe:0.177956\ttrain-rmspe:0.156657\n",
      "[62]\teval-rmse:0.136119\ttrain-rmse:0.133731\teval-rmspe:0.177749\ttrain-rmspe:0.156484\n",
      "[63]\teval-rmse:0.136037\ttrain-rmse:0.133608\teval-rmspe:0.177669\ttrain-rmspe:0.155809\n",
      "[64]\teval-rmse:0.135957\ttrain-rmse:0.133462\teval-rmspe:0.1777\ttrain-rmspe:0.155718\n",
      "[65]\teval-rmse:0.135867\ttrain-rmse:0.13335\teval-rmspe:0.177645\ttrain-rmspe:0.155718\n",
      "[66]\teval-rmse:0.135826\ttrain-rmse:0.133244\teval-rmspe:0.177745\ttrain-rmspe:0.155674\n",
      "[67]\teval-rmse:0.135777\ttrain-rmse:0.132786\teval-rmspe:0.177739\ttrain-rmspe:0.155554\n",
      "[68]\teval-rmse:0.136086\ttrain-rmse:0.132555\teval-rmspe:0.177814\ttrain-rmspe:0.155513\n",
      "[69]\teval-rmse:0.136062\ttrain-rmse:0.132503\teval-rmspe:0.177791\ttrain-rmspe:0.155444\n",
      "[70]\teval-rmse:0.136125\ttrain-rmse:0.132356\teval-rmspe:0.17781\ttrain-rmspe:0.155239\n",
      "[71]\teval-rmse:0.136053\ttrain-rmse:0.132251\teval-rmspe:0.177689\ttrain-rmspe:0.155071\n",
      "[72]\teval-rmse:0.13603\ttrain-rmse:0.132168\teval-rmspe:0.177718\ttrain-rmspe:0.139154\n",
      "[73]\teval-rmse:0.135975\ttrain-rmse:0.132091\teval-rmspe:0.17767\ttrain-rmspe:0.139074\n",
      "[74]\teval-rmse:0.135976\ttrain-rmse:0.132019\teval-rmspe:0.177695\ttrain-rmspe:0.139034\n",
      "[75]\teval-rmse:0.136009\ttrain-rmse:0.132005\teval-rmspe:0.177863\ttrain-rmspe:0.139023\n",
      "[76]\teval-rmse:0.135927\ttrain-rmse:0.131918\teval-rmspe:0.177676\ttrain-rmspe:0.138924\n",
      "[77]\teval-rmse:0.135892\ttrain-rmse:0.131807\teval-rmspe:0.177635\ttrain-rmspe:0.13885\n",
      "[78]\teval-rmse:0.135919\ttrain-rmse:0.131773\teval-rmspe:0.177757\ttrain-rmspe:0.138837\n",
      "[79]\teval-rmse:0.135898\ttrain-rmse:0.131736\teval-rmspe:0.177736\ttrain-rmspe:0.138782\n",
      "[80]\teval-rmse:0.135901\ttrain-rmse:0.131597\teval-rmspe:0.177755\ttrain-rmspe:0.138701\n",
      "[81]\teval-rmse:0.135834\ttrain-rmse:0.131236\teval-rmspe:0.177631\ttrain-rmspe:0.138475\n",
      "[82]\teval-rmse:0.135842\ttrain-rmse:0.131107\teval-rmspe:0.177618\ttrain-rmspe:0.138495\n",
      "[83]\teval-rmse:0.135806\ttrain-rmse:0.131038\teval-rmspe:0.17759\ttrain-rmspe:0.138408\n",
      "[84]\teval-rmse:0.135814\ttrain-rmse:0.130907\teval-rmspe:0.177575\ttrain-rmspe:0.138315\n",
      "[85]\teval-rmse:0.135634\ttrain-rmse:0.13073\teval-rmspe:0.177461\ttrain-rmspe:0.13814\n",
      "[86]\teval-rmse:0.135608\ttrain-rmse:0.130668\teval-rmspe:0.17744\ttrain-rmspe:0.138055\n",
      "[87]\teval-rmse:0.135584\ttrain-rmse:0.13054\teval-rmspe:0.177449\ttrain-rmspe:0.138028\n",
      "[88]\teval-rmse:0.135694\ttrain-rmse:0.130455\teval-rmspe:0.177485\ttrain-rmspe:0.137986\n",
      "[89]\teval-rmse:0.135685\ttrain-rmse:0.130416\teval-rmspe:0.177572\ttrain-rmspe:0.137956\n",
      "[90]\teval-rmse:0.135631\ttrain-rmse:0.130343\teval-rmspe:0.177548\ttrain-rmspe:0.137853\n",
      "[91]\teval-rmse:0.13562\ttrain-rmse:0.130301\teval-rmspe:0.17754\ttrain-rmspe:0.137818\n",
      "[92]\teval-rmse:0.135389\ttrain-rmse:0.13007\teval-rmspe:0.177439\ttrain-rmspe:0.137699\n",
      "[93]\teval-rmse:0.135338\ttrain-rmse:0.129976\teval-rmspe:0.177451\ttrain-rmspe:0.137599\n",
      "[94]\teval-rmse:0.135318\ttrain-rmse:0.12994\teval-rmspe:0.177451\ttrain-rmspe:0.13756\n",
      "[95]\teval-rmse:0.135293\ttrain-rmse:0.129892\teval-rmspe:0.177386\ttrain-rmspe:0.137499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96]\teval-rmse:0.135237\ttrain-rmse:0.12977\teval-rmspe:0.177258\ttrain-rmspe:0.137353\n",
      "[97]\teval-rmse:0.135412\ttrain-rmse:0.129652\teval-rmspe:0.177292\ttrain-rmspe:0.137343\n",
      "[98]\teval-rmse:0.135373\ttrain-rmse:0.129567\teval-rmspe:0.177241\ttrain-rmspe:0.137281\n",
      "[99]\teval-rmse:0.135323\ttrain-rmse:0.129395\teval-rmspe:0.177156\ttrain-rmspe:0.137162\n",
      "[100]\teval-rmse:0.135272\ttrain-rmse:0.129324\teval-rmspe:0.177128\ttrain-rmspe:0.137094\n",
      "[101]\teval-rmse:0.135195\ttrain-rmse:0.129241\teval-rmspe:0.177082\ttrain-rmspe:0.137018\n",
      "[102]\teval-rmse:0.135134\ttrain-rmse:0.129169\teval-rmspe:0.177013\ttrain-rmspe:0.136926\n",
      "[103]\teval-rmse:0.135195\ttrain-rmse:0.129013\teval-rmspe:0.177348\ttrain-rmspe:0.136652\n",
      "[104]\teval-rmse:0.135188\ttrain-rmse:0.128992\teval-rmspe:0.177329\ttrain-rmspe:0.136609\n",
      "[105]\teval-rmse:0.135206\ttrain-rmse:0.128975\teval-rmspe:0.177357\ttrain-rmspe:0.136591\n",
      "[106]\teval-rmse:0.135203\ttrain-rmse:0.128909\teval-rmspe:0.177366\ttrain-rmspe:0.136528\n",
      "[107]\teval-rmse:0.135194\ttrain-rmse:0.12889\teval-rmspe:0.177361\ttrain-rmspe:0.136512\n",
      "[108]\teval-rmse:0.135179\ttrain-rmse:0.128874\teval-rmspe:0.177346\ttrain-rmspe:0.136503\n",
      "[109]\teval-rmse:0.135098\ttrain-rmse:0.128794\teval-rmspe:0.177245\ttrain-rmspe:0.136425\n",
      "[110]\teval-rmse:0.135077\ttrain-rmse:0.128759\teval-rmspe:0.177243\ttrain-rmspe:0.136367\n",
      "[111]\teval-rmse:0.135064\ttrain-rmse:0.128654\teval-rmspe:0.177283\ttrain-rmspe:0.136289\n",
      "[112]\teval-rmse:0.135054\ttrain-rmse:0.128639\teval-rmspe:0.177306\ttrain-rmspe:0.136274\n",
      "[113]\teval-rmse:0.135033\ttrain-rmse:0.128603\teval-rmspe:0.177265\ttrain-rmspe:0.136226\n",
      "[114]\teval-rmse:0.135017\ttrain-rmse:0.128563\teval-rmspe:0.177198\ttrain-rmspe:0.136136\n",
      "[115]\teval-rmse:0.134912\ttrain-rmse:0.128401\teval-rmspe:0.177174\ttrain-rmspe:0.136002\n",
      "[116]\teval-rmse:0.134848\ttrain-rmse:0.128333\teval-rmspe:0.177147\ttrain-rmspe:0.135931\n",
      "[117]\teval-rmse:0.134827\ttrain-rmse:0.128307\teval-rmspe:0.177136\ttrain-rmspe:0.1359\n",
      "[118]\teval-rmse:0.134831\ttrain-rmse:0.128158\teval-rmspe:0.177118\ttrain-rmspe:0.136111\n",
      "[119]\teval-rmse:0.134988\ttrain-rmse:0.128092\teval-rmspe:0.17726\ttrain-rmspe:0.136075\n",
      "[120]\teval-rmse:0.13498\ttrain-rmse:0.128043\teval-rmspe:0.177252\ttrain-rmspe:0.136026\n",
      "[121]\teval-rmse:0.134933\ttrain-rmse:0.127888\teval-rmspe:0.177225\ttrain-rmspe:0.135963\n",
      "[122]\teval-rmse:0.134822\ttrain-rmse:0.127786\teval-rmspe:0.177238\ttrain-rmspe:0.135801\n",
      "[123]\teval-rmse:0.134839\ttrain-rmse:0.127726\teval-rmspe:0.177229\ttrain-rmspe:0.135763\n",
      "[124]\teval-rmse:0.134838\ttrain-rmse:0.127674\teval-rmspe:0.177238\ttrain-rmspe:0.135745\n",
      "[125]\teval-rmse:0.134834\ttrain-rmse:0.127645\teval-rmspe:0.177223\ttrain-rmspe:0.135672\n",
      "[126]\teval-rmse:0.134784\ttrain-rmse:0.127577\teval-rmspe:0.177252\ttrain-rmspe:0.135602\n",
      "[127]\teval-rmse:0.134776\ttrain-rmse:0.127568\teval-rmspe:0.177202\ttrain-rmspe:0.135576\n",
      "[128]\teval-rmse:0.134716\ttrain-rmse:0.127485\teval-rmspe:0.177129\ttrain-rmspe:0.135484\n",
      "[129]\teval-rmse:0.134662\ttrain-rmse:0.127461\teval-rmspe:0.17689\ttrain-rmspe:0.135437\n",
      "[130]\teval-rmse:0.134628\ttrain-rmse:0.127402\teval-rmspe:0.176885\ttrain-rmspe:0.135387\n",
      "[131]\teval-rmse:0.134621\ttrain-rmse:0.127286\teval-rmspe:0.17698\ttrain-rmspe:0.135345\n",
      "[132]\teval-rmse:0.134593\ttrain-rmse:0.127081\teval-rmspe:0.176977\ttrain-rmspe:0.135292\n",
      "[133]\teval-rmse:0.134576\ttrain-rmse:0.126982\teval-rmspe:0.177076\ttrain-rmspe:0.135187\n",
      "[134]\teval-rmse:0.134569\ttrain-rmse:0.126979\teval-rmspe:0.177022\ttrain-rmspe:0.135181\n",
      "[135]\teval-rmse:0.134523\ttrain-rmse:0.126929\teval-rmspe:0.176946\ttrain-rmspe:0.135129\n",
      "[136]\teval-rmse:0.134501\ttrain-rmse:0.126814\teval-rmspe:0.176903\ttrain-rmspe:0.135075\n",
      "[137]\teval-rmse:0.134478\ttrain-rmse:0.126768\teval-rmspe:0.176888\ttrain-rmspe:0.135028\n",
      "[138]\teval-rmse:0.134503\ttrain-rmse:0.12676\teval-rmspe:0.176983\ttrain-rmspe:0.135017\n",
      "[139]\teval-rmse:0.134469\ttrain-rmse:0.126699\teval-rmspe:0.176821\ttrain-rmspe:0.13496\n",
      "[140]\teval-rmse:0.13444\ttrain-rmse:0.126653\teval-rmspe:0.176774\ttrain-rmspe:0.134929\n",
      "[141]\teval-rmse:0.134419\ttrain-rmse:0.126611\teval-rmspe:0.17675\ttrain-rmspe:0.134897\n",
      "[142]\teval-rmse:0.134385\ttrain-rmse:0.126558\teval-rmspe:0.17672\ttrain-rmspe:0.134756\n",
      "[143]\teval-rmse:0.134338\ttrain-rmse:0.126481\teval-rmspe:0.176675\ttrain-rmspe:0.1351\n",
      "[144]\teval-rmse:0.134303\ttrain-rmse:0.126475\teval-rmspe:0.17661\ttrain-rmspe:0.135084\n",
      "[145]\teval-rmse:0.134323\ttrain-rmse:0.126355\teval-rmspe:0.17662\ttrain-rmspe:0.135063\n",
      "[146]\teval-rmse:0.134325\ttrain-rmse:0.126328\teval-rmspe:0.176642\ttrain-rmspe:0.135018\n",
      "[147]\teval-rmse:0.134286\ttrain-rmse:0.126281\teval-rmspe:0.176615\ttrain-rmspe:0.134938\n",
      "[148]\teval-rmse:0.134273\ttrain-rmse:0.126246\teval-rmspe:0.176646\ttrain-rmspe:0.134908\n",
      "[149]\teval-rmse:0.134264\ttrain-rmse:0.12623\teval-rmspe:0.176629\ttrain-rmspe:0.134877\n",
      "[150]\teval-rmse:0.134233\ttrain-rmse:0.126143\teval-rmspe:0.176642\ttrain-rmspe:0.134876\n",
      "[151]\teval-rmse:0.1342\ttrain-rmse:0.126097\teval-rmspe:0.176641\ttrain-rmspe:0.134814\n",
      "[152]\teval-rmse:0.13424\ttrain-rmse:0.126083\teval-rmspe:0.176792\ttrain-rmspe:0.13481\n",
      "[153]\teval-rmse:0.134234\ttrain-rmse:0.126069\teval-rmspe:0.176734\ttrain-rmspe:0.134804\n",
      "[154]\teval-rmse:0.134254\ttrain-rmse:0.126017\teval-rmspe:0.176755\ttrain-rmspe:0.134783\n",
      "[155]\teval-rmse:0.13427\ttrain-rmse:0.125947\teval-rmspe:0.176791\ttrain-rmspe:0.134743\n",
      "[156]\teval-rmse:0.134282\ttrain-rmse:0.125927\teval-rmspe:0.176788\ttrain-rmspe:0.134713\n",
      "[157]\teval-rmse:0.134274\ttrain-rmse:0.125913\teval-rmspe:0.176801\ttrain-rmspe:0.134703\n",
      "[158]\teval-rmse:0.134279\ttrain-rmse:0.125898\teval-rmspe:0.176771\ttrain-rmspe:0.134673\n",
      "[159]\teval-rmse:0.134256\ttrain-rmse:0.125814\teval-rmspe:0.176713\ttrain-rmspe:0.134655\n",
      "[160]\teval-rmse:0.134252\ttrain-rmse:0.125807\teval-rmspe:0.176694\ttrain-rmspe:0.134639\n",
      "[161]\teval-rmse:0.134221\ttrain-rmse:0.125763\teval-rmspe:0.176686\ttrain-rmspe:0.134581\n",
      "[162]\teval-rmse:0.134207\ttrain-rmse:0.125687\teval-rmspe:0.17668\ttrain-rmspe:0.134555\n",
      "[163]\teval-rmse:0.134204\ttrain-rmse:0.125675\teval-rmspe:0.176671\ttrain-rmspe:0.134531\n",
      "[164]\teval-rmse:0.134222\ttrain-rmse:0.125617\teval-rmspe:0.176909\ttrain-rmspe:0.134495\n",
      "[165]\teval-rmse:0.134282\ttrain-rmse:0.125603\teval-rmspe:0.176933\ttrain-rmspe:0.13437\n",
      "[166]\teval-rmse:0.134294\ttrain-rmse:0.125573\teval-rmspe:0.177008\ttrain-rmspe:0.134301\n",
      "[167]\teval-rmse:0.134277\ttrain-rmse:0.125555\teval-rmspe:0.176978\ttrain-rmspe:0.13427\n",
      "[168]\teval-rmse:0.13428\ttrain-rmse:0.125544\teval-rmspe:0.17698\ttrain-rmspe:0.134243\n",
      "[169]\teval-rmse:0.134265\ttrain-rmse:0.125524\teval-rmspe:0.176891\ttrain-rmspe:0.13421\n",
      "[170]\teval-rmse:0.13425\ttrain-rmse:0.125508\teval-rmspe:0.176929\ttrain-rmspe:0.134185\n",
      "[171]\teval-rmse:0.13422\ttrain-rmse:0.12547\teval-rmspe:0.176903\ttrain-rmspe:0.134124\n",
      "[172]\teval-rmse:0.13419\ttrain-rmse:0.125428\teval-rmspe:0.176878\ttrain-rmspe:0.13406\n",
      "[173]\teval-rmse:0.134169\ttrain-rmse:0.125386\teval-rmspe:0.176944\ttrain-rmspe:0.134005\n",
      "[174]\teval-rmse:0.134145\ttrain-rmse:0.125251\teval-rmspe:0.177344\ttrain-rmspe:0.133912\n",
      "[175]\teval-rmse:0.134189\ttrain-rmse:0.125238\teval-rmspe:0.177522\ttrain-rmspe:0.133913\n",
      "[176]\teval-rmse:0.134152\ttrain-rmse:0.125196\teval-rmspe:0.177533\ttrain-rmspe:0.133892\n",
      "[177]\teval-rmse:0.134147\ttrain-rmse:0.125175\teval-rmspe:0.17753\ttrain-rmspe:0.133851\n",
      "[178]\teval-rmse:0.134133\ttrain-rmse:0.125084\teval-rmspe:0.177449\ttrain-rmspe:0.133828\n",
      "[179]\teval-rmse:0.134118\ttrain-rmse:0.125053\teval-rmspe:0.177474\ttrain-rmspe:0.133791\n",
      "[180]\teval-rmse:0.134093\ttrain-rmse:0.124999\teval-rmspe:0.177462\ttrain-rmspe:0.133634\n",
      "[181]\teval-rmse:0.134078\ttrain-rmse:0.124972\teval-rmspe:0.177507\ttrain-rmspe:0.133606\n",
      "[182]\teval-rmse:0.134086\ttrain-rmse:0.124946\teval-rmspe:0.177527\ttrain-rmspe:0.133552\n",
      "[183]\teval-rmse:0.134079\ttrain-rmse:0.124926\teval-rmspe:0.177521\ttrain-rmspe:0.133539\n",
      "[184]\teval-rmse:0.134045\ttrain-rmse:0.124829\teval-rmspe:0.177493\ttrain-rmspe:0.133474\n",
      "[185]\teval-rmse:0.133997\ttrain-rmse:0.124732\teval-rmspe:0.177484\ttrain-rmspe:0.13346\n",
      "[186]\teval-rmse:0.133969\ttrain-rmse:0.124661\teval-rmspe:0.177485\ttrain-rmspe:0.133391\n",
      "[187]\teval-rmse:0.133969\ttrain-rmse:0.12459\teval-rmspe:0.17746\ttrain-rmspe:0.133377\n",
      "[188]\teval-rmse:0.133949\ttrain-rmse:0.124564\teval-rmspe:0.177404\ttrain-rmspe:0.133368\n",
      "[189]\teval-rmse:0.133943\ttrain-rmse:0.124544\teval-rmspe:0.177397\ttrain-rmspe:0.133331\n",
      "[190]\teval-rmse:0.133965\ttrain-rmse:0.124522\teval-rmspe:0.177479\ttrain-rmspe:0.133297\n",
      "[191]\teval-rmse:0.134064\ttrain-rmse:0.12447\teval-rmspe:0.177719\ttrain-rmspe:0.133271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192]\teval-rmse:0.134068\ttrain-rmse:0.124436\teval-rmspe:0.177738\ttrain-rmspe:0.133234\n",
      "[193]\teval-rmse:0.134097\ttrain-rmse:0.124431\teval-rmspe:0.177778\ttrain-rmspe:0.133212\n",
      "[194]\teval-rmse:0.134088\ttrain-rmse:0.1244\teval-rmspe:0.177747\ttrain-rmspe:0.133183\n",
      "[195]\teval-rmse:0.134089\ttrain-rmse:0.12436\teval-rmspe:0.1777\ttrain-rmspe:0.133162\n",
      "[196]\teval-rmse:0.134085\ttrain-rmse:0.124346\teval-rmspe:0.177699\ttrain-rmspe:0.133134\n",
      "[197]\teval-rmse:0.134082\ttrain-rmse:0.124331\teval-rmspe:0.177691\ttrain-rmspe:0.133113\n",
      "[198]\teval-rmse:0.134078\ttrain-rmse:0.124303\teval-rmspe:0.177752\ttrain-rmspe:0.133098\n",
      "[199]\teval-rmse:0.134033\ttrain-rmse:0.124283\teval-rmspe:0.177706\ttrain-rmspe:0.133028\n",
      "[200]\teval-rmse:0.134032\ttrain-rmse:0.124232\teval-rmspe:0.177799\ttrain-rmspe:0.132995\n",
      "[201]\teval-rmse:0.134007\ttrain-rmse:0.124232\teval-rmspe:0.177774\ttrain-rmspe:0.132988\n",
      "[202]\teval-rmse:0.133979\ttrain-rmse:0.124211\teval-rmspe:0.177697\ttrain-rmspe:0.132978\n",
      "[203]\teval-rmse:0.133994\ttrain-rmse:0.124198\teval-rmspe:0.17772\ttrain-rmspe:0.132958\n",
      "[204]\teval-rmse:0.133998\ttrain-rmse:0.124154\teval-rmspe:0.177758\ttrain-rmspe:0.132938\n",
      "[205]\teval-rmse:0.134016\ttrain-rmse:0.124137\teval-rmspe:0.177783\ttrain-rmspe:0.132922\n",
      "[206]\teval-rmse:0.133913\ttrain-rmse:0.124017\teval-rmspe:0.177724\ttrain-rmspe:0.132802\n",
      "[207]\teval-rmse:0.133909\ttrain-rmse:0.123944\teval-rmspe:0.177845\ttrain-rmspe:0.132692\n",
      "[208]\teval-rmse:0.133902\ttrain-rmse:0.12392\teval-rmspe:0.177884\ttrain-rmspe:0.132691\n",
      "[209]\teval-rmse:0.134355\ttrain-rmse:0.123837\teval-rmspe:0.177882\ttrain-rmspe:0.132674\n",
      "[210]\teval-rmse:0.134372\ttrain-rmse:0.123758\teval-rmspe:0.177896\ttrain-rmspe:0.13264\n",
      "[211]\teval-rmse:0.134339\ttrain-rmse:0.123714\teval-rmspe:0.177998\ttrain-rmspe:0.132637\n",
      "[212]\teval-rmse:0.134324\ttrain-rmse:0.123675\teval-rmspe:0.177943\ttrain-rmspe:0.128185\n",
      "[213]\teval-rmse:0.134311\ttrain-rmse:0.123518\teval-rmspe:0.177974\ttrain-rmspe:0.128109\n",
      "[214]\teval-rmse:0.134301\ttrain-rmse:0.123501\teval-rmspe:0.177977\ttrain-rmspe:0.128096\n",
      "[215]\teval-rmse:0.134283\ttrain-rmse:0.123468\teval-rmspe:0.177934\ttrain-rmspe:0.128049\n",
      "[216]\teval-rmse:0.13428\ttrain-rmse:0.123378\teval-rmspe:0.177931\ttrain-rmspe:0.128033\n",
      "[217]\teval-rmse:0.134387\ttrain-rmse:0.123254\teval-rmspe:0.177929\ttrain-rmspe:0.127942\n",
      "[218]\teval-rmse:0.13441\ttrain-rmse:0.123244\teval-rmspe:0.178191\ttrain-rmspe:0.128549\n",
      "[219]\teval-rmse:0.134405\ttrain-rmse:0.123221\teval-rmspe:0.178209\ttrain-rmspe:0.128536\n",
      "[220]\teval-rmse:0.1344\ttrain-rmse:0.123182\teval-rmspe:0.178209\ttrain-rmspe:0.128521\n",
      "[221]\teval-rmse:0.1344\ttrain-rmse:0.123177\teval-rmspe:0.178194\ttrain-rmspe:0.128503\n",
      "[222]\teval-rmse:0.134396\ttrain-rmse:0.123163\teval-rmspe:0.178227\ttrain-rmspe:0.128468\n",
      "[223]\teval-rmse:0.134394\ttrain-rmse:0.123155\teval-rmspe:0.178269\ttrain-rmspe:0.128459\n",
      "[224]\teval-rmse:0.134374\ttrain-rmse:0.123134\teval-rmspe:0.178053\ttrain-rmspe:0.128416\n",
      "[225]\teval-rmse:0.134397\ttrain-rmse:0.123128\teval-rmspe:0.178121\ttrain-rmspe:0.129362\n",
      "[226]\teval-rmse:0.134398\ttrain-rmse:0.123107\teval-rmspe:0.178104\ttrain-rmspe:0.129348\n",
      "[227]\teval-rmse:0.134559\ttrain-rmse:0.122984\teval-rmspe:0.178143\ttrain-rmspe:0.129319\n",
      "[228]\teval-rmse:0.134529\ttrain-rmse:0.122954\teval-rmspe:0.178117\ttrain-rmspe:0.129278\n",
      "[229]\teval-rmse:0.134538\ttrain-rmse:0.122942\teval-rmspe:0.178137\ttrain-rmspe:0.129246\n",
      "[230]\teval-rmse:0.134522\ttrain-rmse:0.122898\teval-rmspe:0.178131\ttrain-rmspe:0.129203\n",
      "[231]\teval-rmse:0.134519\ttrain-rmse:0.122896\teval-rmspe:0.178137\ttrain-rmspe:0.129205\n",
      "[232]\teval-rmse:0.13452\ttrain-rmse:0.122796\teval-rmspe:0.178128\ttrain-rmspe:0.129183\n",
      "[233]\teval-rmse:0.134521\ttrain-rmse:0.122782\teval-rmspe:0.178136\ttrain-rmspe:0.129166\n",
      "[234]\teval-rmse:0.134514\ttrain-rmse:0.122763\teval-rmspe:0.178118\ttrain-rmspe:0.129138\n",
      "[235]\teval-rmse:0.13454\ttrain-rmse:0.122637\teval-rmspe:0.178123\ttrain-rmspe:0.129054\n",
      "[236]\teval-rmse:0.13454\ttrain-rmse:0.12261\teval-rmspe:0.178158\ttrain-rmspe:0.12903\n",
      "[237]\teval-rmse:0.134512\ttrain-rmse:0.122555\teval-rmspe:0.178115\ttrain-rmspe:0.128878\n",
      "[238]\teval-rmse:0.134499\ttrain-rmse:0.122503\teval-rmspe:0.178101\ttrain-rmspe:0.128836\n",
      "[239]\teval-rmse:0.134527\ttrain-rmse:0.122475\teval-rmspe:0.178109\ttrain-rmspe:0.128833\n",
      "[240]\teval-rmse:0.134526\ttrain-rmse:0.12242\teval-rmspe:0.178081\ttrain-rmspe:0.127506\n",
      "[241]\teval-rmse:0.13454\ttrain-rmse:0.122325\teval-rmspe:0.178082\ttrain-rmspe:0.128201\n",
      "[242]\teval-rmse:0.134548\ttrain-rmse:0.122321\teval-rmspe:0.178115\ttrain-rmspe:0.128196\n",
      "[243]\teval-rmse:0.134546\ttrain-rmse:0.122234\teval-rmspe:0.178138\ttrain-rmspe:0.128183\n",
      "[244]\teval-rmse:0.134533\ttrain-rmse:0.122106\teval-rmspe:0.177936\ttrain-rmspe:0.127911\n",
      "[245]\teval-rmse:0.134523\ttrain-rmse:0.122078\teval-rmspe:0.177918\ttrain-rmspe:0.127852\n",
      "[246]\teval-rmse:0.134515\ttrain-rmse:0.122034\teval-rmspe:0.177912\ttrain-rmspe:0.127829\n",
      "[247]\teval-rmse:0.134471\ttrain-rmse:0.121993\teval-rmspe:0.177879\ttrain-rmspe:0.127782\n",
      "[248]\teval-rmse:0.134466\ttrain-rmse:0.121973\teval-rmspe:0.17795\ttrain-rmspe:0.127759\n",
      "[249]\teval-rmse:0.13448\ttrain-rmse:0.121962\teval-rmspe:0.177967\ttrain-rmspe:0.127752\n",
      "[250]\teval-rmse:0.134479\ttrain-rmse:0.12194\teval-rmspe:0.177877\ttrain-rmspe:0.127684\n",
      "[251]\teval-rmse:0.134469\ttrain-rmse:0.121919\teval-rmspe:0.17799\ttrain-rmspe:0.127684\n",
      "[252]\teval-rmse:0.134466\ttrain-rmse:0.121888\teval-rmspe:0.177999\ttrain-rmspe:0.127642\n",
      "[253]\teval-rmse:0.134538\ttrain-rmse:0.121793\teval-rmspe:0.178018\ttrain-rmspe:0.127628\n",
      "[254]\teval-rmse:0.134543\ttrain-rmse:0.121725\teval-rmspe:0.178154\ttrain-rmspe:0.127607\n",
      "[255]\teval-rmse:0.134565\ttrain-rmse:0.121646\teval-rmspe:0.178327\ttrain-rmspe:0.127606\n",
      "[256]\teval-rmse:0.13457\ttrain-rmse:0.121597\teval-rmspe:0.178334\ttrain-rmspe:0.127578\n",
      "[257]\teval-rmse:0.134587\ttrain-rmse:0.121578\teval-rmspe:0.178436\ttrain-rmspe:0.127531\n",
      "[258]\teval-rmse:0.134574\ttrain-rmse:0.121555\teval-rmspe:0.178412\ttrain-rmspe:0.127486\n",
      "[259]\teval-rmse:0.134569\ttrain-rmse:0.121545\teval-rmspe:0.178427\ttrain-rmspe:0.127477\n",
      "[260]\teval-rmse:0.134549\ttrain-rmse:0.121505\teval-rmspe:0.178412\ttrain-rmspe:0.127165\n",
      "[261]\teval-rmse:0.134552\ttrain-rmse:0.121489\teval-rmspe:0.178426\ttrain-rmspe:0.12686\n",
      "[262]\teval-rmse:0.134527\ttrain-rmse:0.121456\teval-rmspe:0.178403\ttrain-rmspe:0.126807\n",
      "[263]\teval-rmse:0.134537\ttrain-rmse:0.121433\teval-rmspe:0.178364\ttrain-rmspe:0.126789\n",
      "[264]\teval-rmse:0.134524\ttrain-rmse:0.12141\teval-rmspe:0.178369\ttrain-rmspe:0.126768\n",
      "[265]\teval-rmse:0.134487\ttrain-rmse:0.121369\teval-rmspe:0.178336\ttrain-rmspe:0.126729\n",
      "[266]\teval-rmse:0.134481\ttrain-rmse:0.121258\teval-rmspe:0.178281\ttrain-rmspe:0.126728\n",
      "[267]\teval-rmse:0.134463\ttrain-rmse:0.121224\teval-rmspe:0.178252\ttrain-rmspe:0.126365\n",
      "[268]\teval-rmse:0.13446\ttrain-rmse:0.121198\teval-rmspe:0.178205\ttrain-rmspe:0.126246\n",
      "[269]\teval-rmse:0.134466\ttrain-rmse:0.121166\teval-rmspe:0.177994\ttrain-rmspe:0.126129\n",
      "[270]\teval-rmse:0.134462\ttrain-rmse:0.121147\teval-rmspe:0.177997\ttrain-rmspe:0.126078\n",
      "[271]\teval-rmse:0.134458\ttrain-rmse:0.121138\teval-rmspe:0.177985\ttrain-rmspe:0.126066\n",
      "[272]\teval-rmse:0.134468\ttrain-rmse:0.121121\teval-rmspe:0.178097\ttrain-rmspe:0.126062\n",
      "[273]\teval-rmse:0.134473\ttrain-rmse:0.121035\teval-rmspe:0.1781\ttrain-rmspe:0.126059\n",
      "[274]\teval-rmse:0.134351\ttrain-rmse:0.12092\teval-rmspe:0.178054\ttrain-rmspe:0.125864\n",
      "[275]\teval-rmse:0.13435\ttrain-rmse:0.120868\teval-rmspe:0.178049\ttrain-rmspe:0.125801\n",
      "[276]\teval-rmse:0.134357\ttrain-rmse:0.120851\teval-rmspe:0.178097\ttrain-rmspe:0.125794\n",
      "[277]\teval-rmse:0.134321\ttrain-rmse:0.120745\teval-rmspe:0.178062\ttrain-rmspe:0.125721\n",
      "[278]\teval-rmse:0.134673\ttrain-rmse:0.120717\teval-rmspe:0.178138\ttrain-rmspe:0.125656\n",
      "[279]\teval-rmse:0.134641\ttrain-rmse:0.120691\teval-rmspe:0.178112\ttrain-rmspe:0.125639\n",
      "[280]\teval-rmse:0.134644\ttrain-rmse:0.120653\teval-rmspe:0.178158\ttrain-rmspe:0.125604\n",
      "[281]\teval-rmse:0.134647\ttrain-rmse:0.120543\teval-rmspe:0.178144\ttrain-rmspe:0.125572\n",
      "[282]\teval-rmse:0.134623\ttrain-rmse:0.120519\teval-rmspe:0.178119\ttrain-rmspe:0.125545\n",
      "[283]\teval-rmse:0.134555\ttrain-rmse:0.12044\teval-rmspe:0.178031\ttrain-rmspe:0.125433\n",
      "[284]\teval-rmse:0.13455\ttrain-rmse:0.120436\teval-rmspe:0.178015\ttrain-rmspe:0.125422\n",
      "[285]\teval-rmse:0.134578\ttrain-rmse:0.120432\teval-rmspe:0.178281\ttrain-rmspe:0.12541\n",
      "[286]\teval-rmse:0.134579\ttrain-rmse:0.120423\teval-rmspe:0.17824\ttrain-rmspe:0.125407\n",
      "[287]\teval-rmse:0.134589\ttrain-rmse:0.120411\teval-rmspe:0.178243\ttrain-rmspe:0.12539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[288]\teval-rmse:0.134572\ttrain-rmse:0.120396\teval-rmspe:0.178228\ttrain-rmspe:0.125381\n",
      "[289]\teval-rmse:0.134582\ttrain-rmse:0.120391\teval-rmspe:0.178348\ttrain-rmspe:0.125391\n",
      "[290]\teval-rmse:0.134635\ttrain-rmse:0.120364\teval-rmspe:0.178364\ttrain-rmspe:0.125343\n",
      "[291]\teval-rmse:0.134629\ttrain-rmse:0.120348\teval-rmspe:0.178386\ttrain-rmspe:0.125289\n",
      "[292]\teval-rmse:0.134618\ttrain-rmse:0.12032\teval-rmspe:0.178356\ttrain-rmspe:0.125253\n",
      "[293]\teval-rmse:0.134609\ttrain-rmse:0.120272\teval-rmspe:0.178348\ttrain-rmspe:0.125211\n",
      "[294]\teval-rmse:0.134606\ttrain-rmse:0.120256\teval-rmspe:0.178346\ttrain-rmspe:0.125193\n",
      "[295]\teval-rmse:0.134607\ttrain-rmse:0.120239\teval-rmspe:0.17845\ttrain-rmspe:0.125202\n",
      "[296]\teval-rmse:0.134591\ttrain-rmse:0.120213\teval-rmspe:0.178361\ttrain-rmspe:0.125147\n",
      "[297]\teval-rmse:0.134581\ttrain-rmse:0.120191\teval-rmspe:0.178345\ttrain-rmspe:0.125119\n",
      "[298]\teval-rmse:0.134573\ttrain-rmse:0.120138\teval-rmspe:0.178319\ttrain-rmspe:0.125069\n",
      "[299]\teval-rmse:0.134601\ttrain-rmse:0.120081\teval-rmspe:0.178439\ttrain-rmspe:0.125042\n",
      "[300]\teval-rmse:0.134632\ttrain-rmse:0.120066\teval-rmspe:0.178534\ttrain-rmspe:0.125032\n",
      "[301]\teval-rmse:0.134677\ttrain-rmse:0.120061\teval-rmspe:0.178586\ttrain-rmspe:0.12501\n",
      "[302]\teval-rmse:0.134665\ttrain-rmse:0.120053\teval-rmspe:0.178556\ttrain-rmspe:0.124997\n",
      "[303]\teval-rmse:0.135097\ttrain-rmse:0.12003\teval-rmspe:0.178561\ttrain-rmspe:0.124961\n",
      "[304]\teval-rmse:0.135102\ttrain-rmse:0.119997\teval-rmspe:0.178592\ttrain-rmspe:0.124962\n",
      "[305]\teval-rmse:0.135104\ttrain-rmse:0.11998\teval-rmspe:0.178602\ttrain-rmspe:0.124951\n",
      "[306]\teval-rmse:0.13509\ttrain-rmse:0.119932\teval-rmspe:0.178592\ttrain-rmspe:0.124926\n",
      "[307]\teval-rmse:0.135091\ttrain-rmse:0.119898\teval-rmspe:0.178533\ttrain-rmspe:0.124916\n",
      "[308]\teval-rmse:0.135061\ttrain-rmse:0.119889\teval-rmspe:0.178713\ttrain-rmspe:0.124888\n",
      "[309]\teval-rmse:0.135053\ttrain-rmse:0.119883\teval-rmspe:0.178676\ttrain-rmspe:0.124883\n",
      "[310]\teval-rmse:0.135085\ttrain-rmse:0.119872\teval-rmspe:0.178818\ttrain-rmspe:0.124834\n",
      "[311]\teval-rmse:0.13508\ttrain-rmse:0.119852\teval-rmspe:0.178803\ttrain-rmspe:0.124816\n",
      "[312]\teval-rmse:0.135067\ttrain-rmse:0.119837\teval-rmspe:0.178764\ttrain-rmspe:0.124778\n",
      "[313]\teval-rmse:0.13507\ttrain-rmse:0.119821\teval-rmspe:0.178762\ttrain-rmspe:0.124769\n",
      "[314]\teval-rmse:0.135083\ttrain-rmse:0.119817\teval-rmspe:0.178701\ttrain-rmspe:0.124787\n",
      "[315]\teval-rmse:0.135068\ttrain-rmse:0.119738\teval-rmspe:0.178371\ttrain-rmspe:0.124754\n",
      "[316]\teval-rmse:0.135093\ttrain-rmse:0.119662\teval-rmspe:0.178359\ttrain-rmspe:0.124746\n",
      "[317]\teval-rmse:0.135089\ttrain-rmse:0.119643\teval-rmspe:0.178405\ttrain-rmspe:0.124734\n",
      "[318]\teval-rmse:0.135089\ttrain-rmse:0.119621\teval-rmspe:0.178418\ttrain-rmspe:0.124704\n",
      "[319]\teval-rmse:0.135085\ttrain-rmse:0.119611\teval-rmspe:0.178419\ttrain-rmspe:0.124699\n",
      "[320]\teval-rmse:0.135079\ttrain-rmse:0.119594\teval-rmspe:0.178423\ttrain-rmspe:0.124266\n",
      "[321]\teval-rmse:0.135088\ttrain-rmse:0.119516\teval-rmspe:0.178417\ttrain-rmspe:0.12425\n",
      "[322]\teval-rmse:0.135065\ttrain-rmse:0.119477\teval-rmspe:0.1784\ttrain-rmspe:0.124227\n",
      "[323]\teval-rmse:0.135055\ttrain-rmse:0.119462\teval-rmspe:0.178385\ttrain-rmspe:0.124202\n",
      "[324]\teval-rmse:0.135102\ttrain-rmse:0.119399\teval-rmspe:0.178739\ttrain-rmspe:0.124161\n",
      "[325]\teval-rmse:0.135098\ttrain-rmse:0.119363\teval-rmspe:0.178571\ttrain-rmspe:0.124108\n",
      "[326]\teval-rmse:0.135084\ttrain-rmse:0.119356\teval-rmspe:0.178435\ttrain-rmspe:0.124089\n",
      "[327]\teval-rmse:0.13509\ttrain-rmse:0.119344\teval-rmspe:0.178435\ttrain-rmspe:0.124078\n",
      "[328]\teval-rmse:0.135073\ttrain-rmse:0.11933\teval-rmspe:0.1784\ttrain-rmspe:0.12405\n",
      "[329]\teval-rmse:0.135069\ttrain-rmse:0.119309\teval-rmspe:0.178407\ttrain-rmspe:0.124024\n",
      "[330]\teval-rmse:0.135072\ttrain-rmse:0.119296\teval-rmspe:0.178428\ttrain-rmspe:0.124002\n",
      "[331]\teval-rmse:0.135053\ttrain-rmse:0.119305\teval-rmspe:0.178254\ttrain-rmspe:0.123983\n",
      "[332]\teval-rmse:0.135032\ttrain-rmse:0.11929\teval-rmspe:0.178219\ttrain-rmspe:0.123974\n",
      "[333]\teval-rmse:0.135056\ttrain-rmse:0.119284\teval-rmspe:0.17823\ttrain-rmspe:0.123974\n",
      "[334]\teval-rmse:0.135053\ttrain-rmse:0.119267\teval-rmspe:0.178233\ttrain-rmspe:0.123967\n",
      "[335]\teval-rmse:0.135062\ttrain-rmse:0.119247\teval-rmspe:0.178241\ttrain-rmspe:0.12395\n",
      "[336]\teval-rmse:0.135007\ttrain-rmse:0.119244\teval-rmspe:0.178281\ttrain-rmspe:0.123944\n",
      "[337]\teval-rmse:0.134648\ttrain-rmse:0.119239\teval-rmspe:0.178291\ttrain-rmspe:0.12393\n",
      "[338]\teval-rmse:0.134661\ttrain-rmse:0.119191\teval-rmspe:0.178249\ttrain-rmspe:0.123889\n",
      "[339]\teval-rmse:0.134428\ttrain-rmse:0.119192\teval-rmspe:0.178311\ttrain-rmspe:0.123874\n",
      "[340]\teval-rmse:0.134427\ttrain-rmse:0.119189\teval-rmspe:0.178289\ttrain-rmspe:0.123867\n",
      "[341]\teval-rmse:0.134861\ttrain-rmse:0.11915\teval-rmspe:0.178282\ttrain-rmspe:0.12382\n",
      "[342]\teval-rmse:0.134856\ttrain-rmse:0.119131\teval-rmspe:0.178254\ttrain-rmspe:0.123791\n",
      "[343]\teval-rmse:0.134854\ttrain-rmse:0.119069\teval-rmspe:0.17825\ttrain-rmspe:0.123764\n",
      "[344]\teval-rmse:0.134941\ttrain-rmse:0.119021\teval-rmspe:0.178244\ttrain-rmspe:0.123741\n",
      "[345]\teval-rmse:0.134935\ttrain-rmse:0.119004\teval-rmspe:0.178228\ttrain-rmspe:0.123712\n",
      "[346]\teval-rmse:0.13493\ttrain-rmse:0.119003\teval-rmspe:0.178233\ttrain-rmspe:0.123716\n",
      "[347]\teval-rmse:0.134934\ttrain-rmse:0.118993\teval-rmspe:0.17826\ttrain-rmspe:0.123693\n",
      "[348]\teval-rmse:0.134937\ttrain-rmse:0.118986\teval-rmspe:0.178254\ttrain-rmspe:0.123691\n",
      "[349]\teval-rmse:0.134913\ttrain-rmse:0.118967\teval-rmspe:0.178247\ttrain-rmspe:0.12365\n",
      "[350]\teval-rmse:0.134947\ttrain-rmse:0.118957\teval-rmspe:0.178345\ttrain-rmspe:0.123484\n",
      "[351]\teval-rmse:0.134956\ttrain-rmse:0.118954\teval-rmspe:0.178381\ttrain-rmspe:0.12348\n",
      "[352]\teval-rmse:0.134951\ttrain-rmse:0.118934\teval-rmspe:0.178366\ttrain-rmspe:0.123431\n",
      "[353]\teval-rmse:0.134954\ttrain-rmse:0.118923\teval-rmspe:0.178379\ttrain-rmspe:0.123409\n",
      "[354]\teval-rmse:0.134941\ttrain-rmse:0.118898\teval-rmspe:0.178295\ttrain-rmspe:0.123391\n",
      "[355]\teval-rmse:0.134943\ttrain-rmse:0.11888\teval-rmspe:0.178303\ttrain-rmspe:0.123345\n",
      "[356]\teval-rmse:0.134952\ttrain-rmse:0.118866\teval-rmspe:0.178309\ttrain-rmspe:0.123324\n",
      "[357]\teval-rmse:0.134958\ttrain-rmse:0.118861\teval-rmspe:0.178319\ttrain-rmspe:0.123302\n",
      "[358]\teval-rmse:0.134961\ttrain-rmse:0.118845\teval-rmspe:0.178358\ttrain-rmspe:0.12328\n",
      "[359]\teval-rmse:0.134961\ttrain-rmse:0.118832\teval-rmspe:0.178358\ttrain-rmspe:0.12325\n",
      "[360]\teval-rmse:0.134943\ttrain-rmse:0.118804\teval-rmspe:0.178364\ttrain-rmspe:0.123235\n",
      "[361]\teval-rmse:0.134945\ttrain-rmse:0.11876\teval-rmspe:0.178334\ttrain-rmspe:0.123218\n",
      "[362]\teval-rmse:0.134957\ttrain-rmse:0.118697\teval-rmspe:0.178347\ttrain-rmspe:0.123203\n",
      "[363]\teval-rmse:0.134926\ttrain-rmse:0.118693\teval-rmspe:0.178029\ttrain-rmspe:0.123197\n",
      "[364]\teval-rmse:0.134931\ttrain-rmse:0.118677\teval-rmspe:0.178011\ttrain-rmspe:0.123186\n",
      "[365]\teval-rmse:0.134964\ttrain-rmse:0.118664\teval-rmspe:0.178168\ttrain-rmspe:0.123169\n",
      "[366]\teval-rmse:0.134964\ttrain-rmse:0.118656\teval-rmspe:0.178061\ttrain-rmspe:0.123164\n",
      "[367]\teval-rmse:0.134948\ttrain-rmse:0.118625\teval-rmspe:0.178057\ttrain-rmspe:0.12315\n",
      "[368]\teval-rmse:0.134936\ttrain-rmse:0.118615\teval-rmspe:0.178087\ttrain-rmspe:0.123155\n",
      "[369]\teval-rmse:0.134933\ttrain-rmse:0.118608\teval-rmspe:0.178039\ttrain-rmspe:0.123144\n",
      "[370]\teval-rmse:0.134916\ttrain-rmse:0.118604\teval-rmspe:0.177974\ttrain-rmspe:0.123137\n",
      "[371]\teval-rmse:0.134911\ttrain-rmse:0.118572\teval-rmspe:0.177994\ttrain-rmspe:0.123085\n",
      "[372]\teval-rmse:0.135084\ttrain-rmse:0.118545\teval-rmspe:0.178144\ttrain-rmspe:0.123071\n",
      "[373]\teval-rmse:0.135084\ttrain-rmse:0.118526\teval-rmspe:0.178141\ttrain-rmspe:0.123054\n",
      "[374]\teval-rmse:0.135078\ttrain-rmse:0.118518\teval-rmspe:0.178168\ttrain-rmspe:0.123039\n",
      "[375]\teval-rmse:0.135074\ttrain-rmse:0.118489\teval-rmspe:0.178155\ttrain-rmspe:0.123018\n",
      "[376]\teval-rmse:0.13507\ttrain-rmse:0.118481\teval-rmspe:0.178158\ttrain-rmspe:0.123012\n",
      "[377]\teval-rmse:0.135083\ttrain-rmse:0.118467\teval-rmspe:0.178178\ttrain-rmspe:0.122956\n",
      "[378]\teval-rmse:0.135083\ttrain-rmse:0.118458\teval-rmspe:0.178184\ttrain-rmspe:0.122951\n",
      "[379]\teval-rmse:0.135078\ttrain-rmse:0.118437\teval-rmspe:0.178147\ttrain-rmspe:0.121598\n",
      "[380]\teval-rmse:0.135079\ttrain-rmse:0.118428\teval-rmspe:0.178144\ttrain-rmspe:0.121582\n",
      "[381]\teval-rmse:0.135085\ttrain-rmse:0.118398\teval-rmspe:0.178126\ttrain-rmspe:0.121532\n",
      "[382]\teval-rmse:0.135092\ttrain-rmse:0.118386\teval-rmspe:0.17815\ttrain-rmspe:0.121516\n",
      "[383]\teval-rmse:0.135097\ttrain-rmse:0.118374\teval-rmspe:0.178152\ttrain-rmspe:0.121471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[384]\teval-rmse:0.135098\ttrain-rmse:0.118362\teval-rmspe:0.178167\ttrain-rmspe:0.121483\n",
      "[385]\teval-rmse:0.135095\ttrain-rmse:0.118343\teval-rmspe:0.178044\ttrain-rmspe:0.121442\n",
      "[386]\teval-rmse:0.135068\ttrain-rmse:0.118307\teval-rmspe:0.178041\ttrain-rmspe:0.121418\n",
      "[387]\teval-rmse:0.135069\ttrain-rmse:0.11829\teval-rmspe:0.178077\ttrain-rmspe:0.121408\n",
      "[388]\teval-rmse:0.135073\ttrain-rmse:0.118252\teval-rmspe:0.178066\ttrain-rmspe:0.12139\n",
      "[389]\teval-rmse:0.135079\ttrain-rmse:0.118239\teval-rmspe:0.178118\ttrain-rmspe:0.121381\n",
      "[390]\teval-rmse:0.135128\ttrain-rmse:0.118155\teval-rmspe:0.178128\ttrain-rmspe:0.121365\n",
      "[391]\teval-rmse:0.135136\ttrain-rmse:0.118174\teval-rmspe:0.17812\ttrain-rmspe:0.121346\n",
      "[392]\teval-rmse:0.135164\ttrain-rmse:0.118188\teval-rmspe:0.178189\ttrain-rmspe:0.121343\n",
      "[393]\teval-rmse:0.135173\ttrain-rmse:0.118184\teval-rmspe:0.178193\ttrain-rmspe:0.121328\n",
      "[394]\teval-rmse:0.135182\ttrain-rmse:0.118136\teval-rmspe:0.178191\ttrain-rmspe:0.121304\n",
      "[395]\teval-rmse:0.135163\ttrain-rmse:0.118107\teval-rmspe:0.178157\ttrain-rmspe:0.121299\n",
      "[396]\teval-rmse:0.135176\ttrain-rmse:0.118102\teval-rmspe:0.178182\ttrain-rmspe:0.121298\n",
      "[397]\teval-rmse:0.135166\ttrain-rmse:0.118097\teval-rmspe:0.178116\ttrain-rmspe:0.121289\n",
      "[398]\teval-rmse:0.135175\ttrain-rmse:0.118072\teval-rmspe:0.178177\ttrain-rmspe:0.121274\n",
      "[399]\teval-rmse:0.135179\ttrain-rmse:0.118061\teval-rmspe:0.178152\ttrain-rmspe:0.121262\n"
     ]
    }
   ],
   "source": [
    "gbm = xgb.train(params, dtrain, num_trees, evals=watchlist, \\\n",
    "                early_stopping_rounds=50, feval=rmspe_xg, verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_response = gbm.predict(xgb.DMatrix(X_test))\n",
    "invalid_sales = validation_response < 0\n",
    "validation_response[invalid_sales] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17815169563770591"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(np.exp(validation_response) - 1, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
